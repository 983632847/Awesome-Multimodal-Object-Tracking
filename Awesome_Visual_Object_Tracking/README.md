# Awesome Visual Object Tracking
![recent_develop](./recent_Tracker_development.png)


> **Acknowledgements:** This project is used to track the latest progress in single-modal tracking or Visual Object Tracking (VOT), continuing two exceptional GitHub projects: [Visual Tracking Paper List](https://github.com/foolwood/benchmark_results) and [Visual-Tracking-Development](https://github.com/DavidZhangdw/Visual-Tracking-Development). We are grateful for your outstanding contributions @Qiang Wang, @David Zhang.

## Contents
- [Papers](#papers)
    - [Recommendations](#recommendations)
    - [Conference and Journal Papers](#conference-and-journal-papers)
- [Benchmarks](#benchmarks)
- [Distinguished Researchers and Teams](#distinguished-researchers-and-teams)

## Papers
### :star2: Recommendations :star2:

- **VOTSurvey:** Sajid Javed, Martin Danelljan, Fahad Shahbaz Khan, Muhammad Haris Khan, Michael Felsberg, Jiri Matas.<br />
  "Visual Object Tracking with Discriminative Filters and Siamese Networks: A Survey and Outlook." TAPMI (2023).
  [[paper](https://arxiv.org/abs/2112.02838)] 
  
- **DL4VT:** Seyed Mojtaba Marvasti-Zadeh, Li Cheng, Senior Member, Hossein Ghanei-Yakhdan, Shohreh Kasaei, Senior Member.<br />
  "Deep Learning for Visual Tracking: A Comprehensive Survey." ArXiv (2021).
  [[paper](https://arxiv.org/pdf/1912.00535.pdf)] 
  [[code](https://github.com/MMarvasti/Deep-Learning-for-Visual-Tracking-Survey)]
      
- **SAM:** Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C. Berg, Wan-Yen Lo, Piotr Dollár, Ross Girshick.<br />
  "Segment Anything." ArXiv (2023).
  [[paper](https://arxiv.org/pdf/2304.02643v1.pdf)] 
  [[homepage](https://segment-anything.com/)] 
  [[code](https://github.com/facebookresearch/segment-anything)]
  
- **TAM:** Jinyu Yang, Mingqi Gao, Zhe Li, Shang Gao, Fangjing Wang, Feng Zheng.<br />
  "Track Anything: Segment Anything Meets Videos." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2304.11968)] 
  [[code](https://github.com/gaomingqi/Track-Anything)]
  
- **SAM-Track:** Yangming Cheng, Liulei Li, Yuanyou Xu, Xiaodi Li, Zongxin Yang, Wenguan Wang, Yi Yang.<br />
  "Segment-and-Track Anything." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2305.06558)] 
  [[code](https://github.com/z-x-yang/Segment-and-Track-Anything)]
  
- **SEEM:** Xueyan Zou, Jianwei Yang, Hao Zhang, Feng Li, Linjie Li, Jianfeng Gao, Yong Jae Lee.<br />
  "Segment Everything Everywhere All at Once." ArXiv (2023).
  [[paper](https://arxiv.org/pdf/2304.06718v1.pdf)] 
  [[code](https://github.com/UX-Decoder/Segment-Everything-Everywhere-All-At-Once)]

- **SAM-PT:** Frano Rajič, Lei Ke, Yu-Wing Tai, Chi-Keung Tang, Martin Danelljan, Fisher Yu.<br />
  "Segment Anything Meets Point Tracking." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2307.01197)] 
  [[code](https:/github.com/syscv/sam-pt)]
  
- **ReviewLLM:** Jiaqi Wang, Zhengliang Liu, Lin Zhao, Zihao Wu, Chong Ma, Sigang Yu, Haixing Dai.<br />
  "Review of Large Vision Models and Visual Prompt Engineering." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2307.00855)]
  [[code](https://github.com/xxx)]
  
- **ChatVideo:** Junke Wang, Dongdong Chen, Chong Luo, Xiyang Dai, Lu Yuan, Zuxuan Wu, Yu-Gang Jiang.<br />
  "ChatVideo: A Tracklet-centric Multimodal and Versatile Video Understanding System." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2304.14407)] 
  [[code](https://www.wangjunke.info/ChatVideo/)]
  
- **Video-ChatGPT:** Muhammad Maaz, Hanoona Rasheed, Salman Khan, Fahad Shahbaz Khan.<br />
  "Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2306.05424)] 
  [[code](https://github.com/mbzuai-oryx/Video-ChatGPT)]
  
- **SegGPT:** Xinlong Wang, Xiaosong Zhang, Yue Cao, Wen Wang, Chunhua Shen, Tiejun Huang.<br />
  "SegGPT: Segmenting Everything In Context." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2304.03284)] 
  [[code](https://github.com/baaivision/Painter)]

- **VL-SAM2:** Chunhui Zhang, Li Liu, Guanjie Huang, Zhipeng Zhang, Hao Wen, Xi Zhou, Shiming Ge, Yanfeng Wang.<br />
  "Underwater Camouflaged Object Tracking Meets Vision-Language SAM2." CVPR Workshop (2025).
  [[paper](https://arxiv.org/abs/2409.16902)]
  [[project](https://github.com/983632847/Awesome-Multimodal-Object-Tracking/tree/main/UW-COT220)]
  

### :boom: Conference and Journal Papers :boom:
### ArXiv-2025
- **CST Anti-UAV:** Bin Xie, Congxuan Zhang, Fagan Wang, Peng Liu, Feng Lu, Zhen Chen, Weiming Hu.<br />
  "CST Anti-UAV: A Thermal Infrared Benchmark for Tiny UAV Tracking in Complex Scenes." ICCVW (2025).
  [[paper](https://arxiv.org/abs/2507.23473)]
  
- **SAMITE:** Qianxiong Xu, Lanyun Zhu, Chenxi Liu, Guosheng Lin, Cheng Long, Ziyue Li, Rui Zhao.<br />
"SAMITE: Position Prompted SAM2 with Calibrated Memory for Visual Object Tracking." ArXiv (2025).
[[paper](https://arxiv.org/abs/2507.21732)]
[[code](https://github.com/Sam1224/SAMITE)]
[2025.07]

- **HQ-SMem:** Elham Soltani Kazemi, Imad Eddine Toubal, Gani Rahmon, Jaired Collins, K. Palaniappan.<br />
"HQ-SMem: Video Segmentation and Tracking Using Memory Efficient Object Embedding With Selective Update and Self-Supervised Distillation Feedback." ArXiv (2025).
[[paper](https://arxiv.org/abs/2507.18921)]
[2025.07]

- **FWTrack:** Fan, Xuyi and Li, Hongguang and Wang, Yangzhu and Zhao, Minghao and Shen, Li.<br />
  "Hierarchical Spatial–Temporal UAV Tracking With Three-Dimensional Wavelets for Road Traffic Surveillance." TITS (2025).
  [[paper](https://ieeexplore.ieee.org/abstract/document/11087725)] 
  [[code](https://github.com/OrigamiSL/FWTrack)]
  
- **RSTrack:** Fansheng Zeng, Bineng Zhong, Haiying Xia, Yufei Tan, Xiantao Hu, Liangtao Shi, Shuxiang Song.<br />
  "Explicit Context Reasoning with Supervision for Visual Tracking." ACM MM (2025).
  [[paper](https://arxiv.org/abs/2507.16191)] 
  [[code](https://github.com/GXNU-ZhongLab/RSTrack)]
  
- Heegyeong Kim, Alice James, Avishkar Seth, Endrowednes Kuantama, Jane Williamson, Yimeng Feng, Richard Han.<br />
"Continuous Marine Tracking via Autonomous UAV Handoff." DroNet(2025).
[[paper](https://arxiv.org/abs/2507.12763)]
[2025.07]

- **AUDI-T:** Bin Kang and Zongyu Wang and Dong Liang and Tianyu Ding and Songlin Du.<br />
  "Robust Unsupervised Visual Tracking Via Image-to-Video Identity Knowledge Transferring." Pattern Recognition (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0031320325007691)]
  
- **HiM2SAM:** Ruixiang Chen, Guolei Sun, Yawei Li, Jie Qin, Luca Benini.<br />
"HiM2SAM: Enhancing SAM2 with Hierarchical Motion Estimation and Memory Optimization towards Long-term Tracking." ArXiv (2025).
[[paper](https://arxiv.org/abs/2507.07603)]
[[code](https://github.com/LouisFinner/HiM2SAM)]
[2025.07]

- **STAR:** Yuzeng Chen; Qiangqiang Yuan; Yi Xiao; Yuqi Tang; Jiang He; Te Han.<br />
  "STAR: A Unified Spatiotemporal Fusion Framework for Satellite Video Object Tracking." TGRS (2025).
  [[paper](https://ieeexplore.ieee.org/abstract/document/11063306)] 
  [[code](https://github.com/YZCU/STAR)]

- **SiamTITP:** Zhou, Jiawei and Dong, Yanni and Du, Bo.<br />
  "SiamTITP: Incorporating Temporal Information and Trajectory Prediction Siamese Network for Satellite Video Object Tracking." TIP (2025).
  [[paper](https://ieeexplore.ieee.org/abstract/document/11051136)] 
  [[code](https://github.com/jiawei-zhou/SiamTITP)]

- **TMATrack:** Jinguang Chen, Hongxiao Yao & Lili Ma.<br />
  "TMATrack: token merging for autoregressive visual object tracking." The Journal of Supercomputing (2025).
  [[paper](https://link.springer.com/article/10.1007/s11227-025-07498-y)] 

- **Stable-SAM2:** Mohamad Alansari and Iyyakutti Iyappan Ganapathi and Sara Alansari and Hasan Al Marzouqi and Sajid Javed.<br />
  "Visual tracking by matching points using diffusion model." Alexandria Engineering Journal (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S1110016825007914)] 
  [[code](https://github.com/HamadYA/Stable-SAM2)]
  
- **TDAT:** Xue, Yuanliang and Jin, Guodong and Shen, Tao and Tan, Lining and Wang, Nian and Gao, Jing and Yu, Ye and Tian, Siyuan.<br />
  "Target-Distractor Aware UAV Tracking via Global Agent." TITS (2025).
  [[paper](https://ieeexplore.ieee.org/document/11054299)] 
  [[code](https://github.com/xyl-507/TDAT)]
  
- **TrackingMiM:** Bingxi Liu, Calvin Chen, Junhao Li, Guyang Yu, Haoqian Song, Xuchen Liu, Jinqiang Cui, Hong Zhang.<br />
  "TrackingMiM: Efficient Mamba-in-Mamba Serialization for Real-time UAV Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2507.01535)]
  
- **MSAF:** Shaoming Li and Kai Huang and Jun Chu and Lu Leng.<br />
  "MSAF: Multi-Scale Adaptive Filter for Object Tracking." ESWA (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0957417425023334)]
  
- **HiT:** Ben Kang, Xin Chen, Jie Zhao, Chunjuan Bo, Dong Wang, Huchuan Lu .<br />
  "Exploiting Lightweight Hierarchical ViT and Dynamic Framework for Efficient Visual Tracking." IJCV (2025).
  [[paper](https://link.springer.com/article/10.1007/s11263-025-02500-9)] 
  [[code](https://github.com/kangben258/HiT)]

- **MRMACF:** Sathiyamoorthi Arthanari, Jae Hoon Jeong, Young Hoon Joo.<br />
  "Learning multi-regularized mutation-aware correlation filter for object tracking via an adaptive hybrid model." Neural Networks (2025).
  [[paper](https://www.sciencedirect.com/science/article/abs/pii/S0893608025006264)] 

- **HiMTrack:** Ning Li; Bineng Zhong; Qihua Liang; Zhiyi Mo; Shuxiang Song.<br />
  "Robust Multi-stage Tracking via Multi-scale and Multi-level Representation Learning." TMM (2025).
  [[paper](https://ieeexplore.ieee.org/abstract/document/11045528)]
  
- **DiMPLE:** Wang, Jun and Chai, Bingfei and Zhou, Lingtao and Wang, Yuanyun.<br />
  "Robust Object Tracking via Long-Range Spatial Representation and Local Feature Enhancement." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/document/11029262)]
  
- **MVTD:**  Ahsan Baidar Bakht, Muhayy Ud Din, Sajid Javed, Irfan Hussain.<br />
  "MVTD: A Benchmark Dataset for Maritime Visual Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2506.02866)] 
  [[code](https://github.com/AhsanBaidar/MVTD)]

- **DiffDf:** Long Xu, Peng Gao, Wen-Jia Tang, Fei Wang, Ru-Yue Yuan.<br />
  "Towards Effective and Efficient Adversarial Defense with Diffusion Models for Robust Visual Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2506.00325)] 
  [[code](https://github.com/pgao-lab/DiffDf)]
  
- **TrackVLA:**  Shaoan Wang, Jiazhao Zhang, Minghan Li, Jiahang Liu, Anqi Li, Kui Wu, Fangwei Zhong, Junzhi Yu, Zhizheng Zhang, He Wang.<br />
  "TrackVLA: Embodied Visual Tracking in the Wild." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.23189)] 
  [[code](https://pku-epic.github.io/TrackVLA-web)]
  
- **HIEVT:** Kui Wu, Hao Chen, Churan Wang, Fakhri Karray, Zhoujun Li, Yizhou Wang, Fangwei Zhong.<br />
  "Hierarchical Instruction-aware Embodied Visual Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.20710)] 
  [[code](https://sites.google.com/view/hievt)]

- **EVT-Recovery-Assistant:** Kui Wu, Shuhang Xu, Hao Chen, Churan Wang, Zhoujun Li, Yizhou Wang, Fangwei Zhong.<br />
  "VLM Can Be a Good Assistant: Enhancing Embodied Visual Tracking with Self-Improving Visual-Language Models." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.20718)] 
  [[code](https://sites.google.com/view/evt-recovery-assistant)]
  
- **DT-Training:** Jack Hong, Shilin Yan, Zehao Xiao, Jiayin Cai, Xiaolong Jiang, Yao Hu, Henghui Ding.<br />
  "Progressive Scaling Visual Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.19990)]
  
- **DIMM:** Jirong Zha, Yuxuan Fan, Kai Li, Han Li, Chen Gao, Xinlei Chen, Yong Li.<br />
  "DIMM: Decoupled Multi-hierarchy Kalman Filter for 3D Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.12340)]
  
- **MPIT:** Wang, Wuwei and Lv, Meibo and Zhu, Lin and Han, Tuo and Zhang, Yi and Li, Yuanqing.<br />
  "Siamese Visual Tracking with Multi-Parallel Interactive Transformers." TCSVT (2025).
  [[paper](https://ieeexplore.ieee.org/abstract/document/11003183)]
  
- **AMGA:** Wei-Long Tian, Peng Gao, Xiao Liu, Long Xu, Hamido Fujita, Hanan Aljuai, Mao-Li Wang.<br />
  "Towards Adaptive Meta-Gradient Adversarial Examples for Visual Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2505.08999)] 
  [[code](https://github.com/pgao-lab/AMGA)]
  
- **CGTrack:** Weihong Li, Xiaoqiong Liu, Heng Fan, Libo Zhang.<br />
  "CGTrack: Cascade Gating Network with Hierarchical Feature Aggregation for UAV Tracking." ICRA (2025).
  [[paper](https://arxiv.org/abs/2505.05936)] 
  [[code](https://github.com/Nightwatch-Fox11/CGTrack)]
  
- Chenxu Peng, Chenxu Wang, Minrui Zou, Danyang Li, Zhengpeng Yang, Yimian Dai, Ming-Ming Cheng, Xiang Li.<br />
  "A Simple Detector with Frame Dynamics is a Strong Tracker." CVPR Anti-UAV Workshop (2025).
  [[paper](https://arxiv.org/abs/2505.04917)] 
  [[code](https://github.com/facias914/A-Simple-Detector-is-a-Strong-Tracker)]
  
- **DARTer:** Xuzhao Li, Xuchen Li, Shiyu Hu.<br />
  "DARTer: Dynamic Adaptive Representation Tracker for Nighttime UAV Tracking." ICMR (2025).
  [[paper](https://arxiv.org/abs/2505.00752)]
  
- **ATOTrack:** Sixian Chan, Xianpeng Zeng, Zhoujian Wu, Yu Wang, Xiaolong Zhou, Tinglong Tang, Jie Hu.<br />
  "Adaptive Target Oriented Tracking." ACM TIST (2025).
  [[paper](https://dl.acm.org/doi/abs/10.1145/3732785)]
  
- **DSTrack:** Zhixing Wang and Kai Wang and Chuanming Tang and Xiang Li and Jianlin Zhang and Lianli Gao.<br />
  "DSTrack: Diffusion-based sequence learning for visual object tracking." PR (2025).
   [[paper](https://www.sciencedirect.com/science/article/abs/pii/S0031320325003541)]

- **PUTrack:** Zhang, Qiuyang and Song, Wei and Liu, Cong and Zhang, Minghua.<br />
  "PUTrack: Improved Underwater Object Tracking via Progressive Prompting." TII (2025).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10892342)] 
  [[code](https://github.com/faicaiwawa/PUTrack)]
  
- **DMP:** Zihan Zhou, Changrui Dai, Aibo Song, Xiaolin Fang.<br />
  "Enhancing Self-Supervised Fine-Grained Video Object Tracking with Dynamic Memory Prediction." ICMR (2025).
  [[paper](https://arxiv.org/abs/2504.21692)]
  
- **SonarT165:** Yunfeng Li, Bo Wang, Jiahao Wan, Xueyi Wu, Ye Li.<br />
  "SonarT165: A Large-scale Benchmark and STFTrack Framework for Acoustic Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2504.15609)] 
  [[code](https://github.com/LiYunfengLYF/SonarT165)]
  
- **TAPIP3D:** Bowei Zhang, Lei Ke, Adam W. Harley, Katerina Fragkiadaki.<br />
  "TAPIP3D: Tracking Any Point in Persistent 3D Geometry." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2504.14717)] 
  [[code](https://tapip3d.github.io/)]
  
- **FocusTrack:** Ying Wang, Tingfa Xu, Jianan Li.<br />
  "FocusTrack: A Self-Adaptive Local Sampling Algorithm for Efficient Anti-UAV Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2504.13604)]
  [[code](https://github.com/vero1925/FocusTrack)]
  
- **EffOWT:** Bingyang Wang, Kaer Huang, Bin Li, Yiqiang Yan, Lihe Zhang, Huchuan Lu, You He.<br />
  "EffOWT: Transfer Visual Language Models to Open-World Tracking Efficiently and Effectively." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2504.05141)]
  
- **COST:** Chunhui Zhang, Li Liu, Jialin Gao, Xin Sun, Hao Wen, Xi Zhou, Shiming Ge, Yanfeng Wang.<br />
  "COST: Contrastive One-Stage Transformer for Vision-Language Small Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2504.01321)] 
  [[code](https://github.com/983632847/Awesome-Multimodal-Object-Tracking/tree/main/VL-SOT500)]
  
- **TrackingMeetsLMM:** Ayesha Ishaq, Jean Lahoud, Fahad Shahbaz Khan, Salman Khan, Hisham Cholakkal, Rao Muhammad Anwer.<br />
  "Tracking Meets Large Multimodal Models for Driving Scenario Understanding." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2503.14498)] 
  [[code](https://github.com/mbzuai-oryx/TrackingMeetsLMM)]

- **UncTrack:** Siyuan Yao, Yang Guo, Yanyang Yan, Wenqi Ren, Xiaochun Cao.<br />
  "UncTrack: Reliable Visual Object Tracking with Uncertainty-Aware Prototype Memory Network." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2503.12888)] 
  [[code](https://github.com/ManOfStory/UncTrack)]

- **CFTrack:** Juntao Liang, Jun Hou, Weijun Zhang, Yong Wang.<br />
  "CFTrack: Enhancing Lightweight Visual Tracking through Contrastive Learning and Feature Matching." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2502.19705)] 

- **DASTM:** Meng Zhou, Jiadong Xie, Mingsheng Xu.<br />
  "Dynamic Attention Mechanism in Spatiotemporal Memory Networks for Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2503.16768)] 

- **BFTrans:** Xinglong Sun, Haijiang Sun, Shan Jiang, Jiacheng Wang, Jiasong Wang.<br />
  "Target-aware Bidirectional Fusion Transformer for Aerial Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2503.09951)] 

- **HyA-T:** Long Gao, Yunhe Zhang, Langkun Chen, Yan Jiang, Weiying Xie, Yunsong Li.<br />
  "Hyperspectral Adapter for Object Tracking based on Hyperspectral Video." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2503.22199)] 
  [[code](https://github.com/lgao001/HyA-T)]

- Shaheer Mohamed, Tharindu Fernando, Sridha Sridharan, Peyman Moghadam, Clinton Fookes.<br />
  "Spectral-Enhanced Transformers: Leveraging Large-Scale Pretrained Models for Hyperspectral Object Tracking." ArXiv (2025).
  [[paper](https://arxiv.org/abs/2502.18748)]

- **ECTTrack:** Liang Xu and Zhiqing Guo and Liejun Wang.<br />
  "Efficient hybrid linear self-attention based visual object tracking with LoRA." Neurocomputing (2025).
  [[paper](https://www.sciencedirect.com/science/article/pii/S0925231225010070)] 
  [[code](https://github.com/mrlonely426/ECTTrack)]

- **CCTrack:** Wang, Ye and Mei, Shaohui and Ma, Mingyang and Liu, Yuheng and Gao, Tao and Han, Huiyang.<br />
  "Hyperspectral Object Tracking With Context-Aware Learning and Category Consistency." TGRS (2025).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10928989)] 

### ICCV 2025
- **ATCTrack:** X. Feng, S. Hu, X. Li, D. Zhang, M. Wu, J. Zhang, X. Chen, K. Huang.<br />
  "ATCTrack: Aligning Target-Context Cues with Dynamic Target States for Robust Vision-Language Tracking." ICCV (2025).
  [[paper](https://arxiv.org/abs/2507.19875)] 
  [[code](https://github.com/XiaokunFeng/ATCTrack)]
  
- **TAPNext:** Artem Zholus, Carl Doersch, Yi Yang, Skanda Koppula, Viorica Patraucean, Xu Owen He, Ignacio Rocco, Mehdi S. M. Sajjadi, Sarath Chandar, Ross Goroshin.<br />
  "TAPNext: Tracking Any Point (TAP) as Next Token Prediction." ICCV (2025).
  [[paper](https://arxiv.org/abs/2504.05579)]
  
- **TUEs:** Qiangqiang Wu, Yi Yu, Chenqi Kong, Ziquan Liu, Jia Wan, Haoliang Li, Alex C. Kot, Antoni B. Chan.<br />
  "Temporal Unlearnable Examples: Preventing Personal Video Data from Unauthorized Exploitation by Object Tracking." ICCV (2025).
  [[paper](https://arxiv.org/abs/2507.07483)]
  
- **FlexTrack:** Yuedong Tan, Jiawei Shao, Eduard Zamfir, Ruanjun Li, Zhaochong An, Chao Ma, Danda Paudel, Luc Van Gool, Radu Timofte, Zongwei Wu.<br />
  "What You Have is What You Track: Adaptive and Robust Multimodal Tracking." ICCV (2025).
  [[paper](https://arxiv.org/abs/2507.05899)] 
  [[code](https://github.com/supertyd/FlexTrack/tree/main)]
  
- **UMDATrack:** Siyuan Yao, Rui Zhu, Ziqi Wang, Wenqi Ren, Yanyang Yan, Xiaochun Cao.<br />
  "UMDATrack: Unified Multi-Domain Adaptive Tracking Under Adverse Weather Conditions." ICCV (2025).
  [[paper](https://arxiv.org/abs/2507.00648)] 
  [[code](https://github.com/Z-Z188/UMDATrack)]

- **SpatialTrackerV2:** Yuxi Xiao, Jianyuan Wang, Nan Xue, Nikita Karaev, Yuri Makarov, Bingyi Kang, Xing Zhu, Hujun Bao, Yujun Shen, Xiaowei Zhou.<br />
  "SpatialTrackerV2: 3D Point Tracking Made Easy." ICCV (2025).
  [[paper](https://arxiv.org/abs/2507.12462)] 
  [[code](https://huggingface.co/spaces/Yuxihenry/SpatialTrackerV2)]

### CVPR 2025
- **DreamTrack:** Mingzhe Guo, Weiping Tan, Wenyu Ran, Liping Jing, Liping Jing, Zhipeng Zhang.<br />
  "DreamTrack: Dreaming the Future for Multimodal Visual Object Tracking." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_DreamTrack_Dreaming_the_Future_for_Multimodal_Visual_Object_Tracking_CVPR_2025_paper.pdf)] 

- **JTD-UAV:** Yifan Wang, Jian Zhao, Zhaoxin Fan, Xin Zhang, Xuecheng Wu, Yudian Zhang, Lei Jin, Xinyue Li, Gang Wang, Mengxi Jia, Ping Hu, Zheng Zhu, Xuelong Li.<br />
  "JTD-UAV: MLLM-Enhanced Joint Tracking and Description Framework for Anti-UAV Systems." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_JTD-UAV_MLLM-Enhanced_Joint_Tracking_and_Description_Framework_for_Anti-UAV_Systems_CVPR_2025_paper.pdf)] 


- **SAM2.1++:** Jovana Videnovic, Alan Lukezic, Matej Kristan.<br />
"A Distractor-Aware Memory for Visual Object Tracking with SAM2." CVPR (2025).
[[paper](https://arxiv.org/abs/2411.17576)]
[[code](https://github.com/jovanavidenovic/DAM4SAM)]

- **EdgeTAM:** Chong Zhou, Chenchen Zhu, Yunyang Xiong, Saksham Suri, Fanyi Xiao, Lemeng Wu, Raghuraman Krishnamoorthi, Bo Dai, Chen Change Loy, Vikas Chandra, Bilge Soran.<br />
  "EdgeTAM: On-Device Track Anything Model." CVPR (2025).
  [[paper](https://arxiv.org/abs/2501.07256)] 
  [[code](https://github.com/facebookresearch/EdgeTAM)]
  
- **MambaVLT:** Xinqi Liu, Li Zhou, Zikun Zhou, Jianqiu Chen, Zhenyu He.<br />
  "MambaVLT: Time-Evolving Multimodal State Space Model for Vision-Language Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2411.15459)]

- **PURA:** Zekai Shao, Yufan Hu, Bin Fan, Hongmin Liu.<br />
  "PURA: Parameter Update-Recovery Test-Time Adaption for RGB-T Tracking." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/papers/Shao_PURA_Parameter_Update-Recovery_Test-Time_Adaption_for_RGB-T_Tracking_CVPR_2025_paper.pdf)] 
  [[code](https://melantech.github.io/PURA)]
  
- **MamTrack:** Chuanyu Sun, Jiqing Zhang, Yang Wang, Huilin Ge, qianchen xia, Baocai Yin, Xin Yang.<br />
  "Exploring Historical Information for RGBE Visual Tracking with Mamba." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Exploring_Historical_Information_for_RGBE_Visual_Tracking_with_Mamba_CVPR_2025_paper.pdf)] 
  [[code](https://github.com/scy0712/MamTrack)]

- **SGLATrack:** Chaocan Xue, Bineng Zhong, Qihua Liang, Yaozong Zheng, Ning Li, Yuanliang Xue, Shuxiang Song.<br />
  "Similarity-Guided Layer-Adaptive Vision Transformer for UAV Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2503.06625)] 
  [[code](https://github.com/GXNU-ZhongLab/SGLATrack.)]

- **DUTrack:** Xiaohai Li, Bineng Zhong, Qihua Liang, Zhiyi Mo, Jian Nong, Shuxiang Song.<br />
  "Dynamic Updates for Language Adaptation in Visual-Language Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2503.06621)] 
  [[code](https://github.com/GXNU-ZhongLab/DUTrack)]
  
- **MITracker:** Mengjie Xu, Yitao Zhu, Haotian Jiang, Jiaming Li, Zhenrong Shen, Sheng Wang, Haolin Huang, Xinyu Wang, Qing Yang, Han Zhang, Qian Wang.<br />
  "MITracker: Multi-View Integration for Visual Object Tracking." CVPR 2025 (2025).
  [[paper](https://arxiv.org/abs/2502.20111)] 
  [[code](https://github.com/XuM007/MITracker)]
  [[project](https://mii-laboratory.github.io/MITracker/)]

- Xiuqiang Song · Li Jin · Zhengxian Zhang · Jiachen Li · Fan Zhong · Guofeng Zhang · Xueying Qin.<br />
  "Prior-free 3D Object Tracking." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/papers/Song_Prior-free_3D_Object_Tracking_CVPR_2025_paper.pdf)] 
  [[code](https://github.com/songxiuqiang/BIT.git)]

- **Tracktention:** Zihang Lai, Andrea Vedaldi.<br />
  "Tracktention: Leveraging Point Tracking to Attend Videos Faster and Better." CVPR (2025).
  [[paper](https://arxiv.org/abs/2503.19904)] 
  [[code](https://zlai0.github.io/TrackTention/)]
  
- **Chrono:** Inès Hyeonsu Kim · Seokju Cho · Seokju Cho · Gabriel Huang · Jung Yi · Joon-Young Lee · Seungryong Kim.<br />
  "Exploring Temporally-Aware Features for Point Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2501.12218)] 
  [[code](https://github.com/cvlab-kaist/Chrono)]
  [[project](https://cvlab-kaist.github.io/Chrono/)]

- **Mono3DVLT:** Hongkai Wei · YANG YANG · Shijie Sun · Mingtao Feng · Xiangyu Song · Qi Lei · Hongli Hu · Rong Wang · Huansheng Song · Naveed Akhtar · Ajmal Mian.<br />
  "Mono3DVLT: Monocular-Video-Based 3D Visual Language Tracking." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/papers/Wei_Mono3DVLT_Monocular-Video-Based_3D_Visual_Language_Tracking_CVPR_2025_paper.pdf)] 
  [[code](https://github.com/hongkai-wei/Mono3DVLT)]

- **MUST:** Haolin Qin, Tingfa Xu, Tianhao Li, Zhenxiang Chen, Tao Feng, Jianan Li.<br />
  "MUST: The First Dataset and Unified Framework for Multispectral UAV Single Object Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2503.17699)] 
  [[code](https://github.com/q2479036243/MUST-Multispectral-UAV-Single-Object-Tracking)]

- **SPMTrack:** Wenrui Cai · Qingjie Liu · Yunhong Wang.<br />
  "SPMTrack: Spatio-Temporal Parameter-Efficient Fine-Tuning with Mixture of Experts for Scalable Visual Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2503.18338)] 
  [[code](https://github.com/WenRuiCai/SPMTrack)]

- Shiyi Liang · Yifan Bai · Yihong Gong · Xing Wei.<br />
  "Autoregressive Sequential Pretraining for Visual Tracking." CVPR (2025).
  [[paper](https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Autoregressive_Sequential_Pretraining_for_Visual_Tracking_CVPR_2025_paper.pdf)] 
  [[code](https://arptrack.github.io/)]

- **ORTrack:** You Wu · Xucheng Wang · Xiangyang Yang · Mengyuan Liu · Dan Zeng · Hengzhou Ye · Shuiwang Li.<br />
  "Learning Occlusion-Robust Vision Transformers for Real-Time UAV Tracking." CVPR (2025).
  [[paper](https://arxiv.org/abs/2504.09228)] 
  [[code](https://github.com/wuyou3474/ORTrack)]

- **OmniTrack:** Kai Luo · Hao Shi · Sheng Wu · Fei Teng · Mengfei Duan · Chang Huang · Yuhang Wang · Kaiwei Wang · Kailun Yang.<br />
  "OmniTrack: Omnidirectional Multi-Object Tracking." CVPR (2025).
  [[paper](https://arxiv.org/pdf/2503.04565)] 
  [[code](https://github.com/xifen523/OmniTrack)]  
  
### ICML 2025
- **MPT:** Jie Zhao, Xin Chen, Yongsheng Yuan, Michael Felsberg, Dong Wang, Huchuan Lu.<br />
  "Efficient Motion Prompt Learning for Robust Visual Tracking." ICML(2025).
  [[paper](https://arxiv.org/abs/2505.16321)] 
  [[code](https://github.com/zj5559/Motion-Prompt-Tracking)]
  
### ICLR 2025
- **Track-On:** Görkay Aydemir, Xiongyi Cai, Weidi Xie, Fatma Guney.<br />
  "Track-On: Transformer-based Online Point Tracking with Memory." ArXiv (2025).
  [[paper](https://openreview.net/attachment?id=oRlANEuqG5&name=pdf)] 
  [[code](https://kuis-ai.github.io/track_on)]


### AAAI 2025 
- **SUTrack:** Xin Chen, Ben Kang, Wanting Geng, Jiawen Zhu, Yi Liu, Dong Wang, Huchuan Lu.<br />
  "SUTrack: Towards Simple and Unified Single Object Tracking." AAAI (2025).
  [[paper](https://arxiv.org/abs/2412.19138)] 
  [[code](https://github.com/chenxin-dlut/SUTrack)]

- **MCITrack:** Ben Kang, Xin Chen, Simiao Lai, Yang Liu, Yi Liu, Dong Wang.<br />
  "Exploring Enhanced Contextual Information for Video-Level Object Tracking." AAAI (2025).
  [[paper](https://arxiv.org/abs/2412.11023)] 
  [[code](https://github.com/kangben258/MCITrack)]

- **MambaLCT:** Xiaohai Li, Bineng Zhong, Qihua Liang, Guorong Li, Zhiyi Mo, Shuxiang Song.<br />
   "Boosting Tracking via Long-term Context State Space Model." AAAI (2025).
    [[Paper](https://arxiv.org/abs/2412.13615)]
    [[code](https://github.com/GXNU-ZhongLab/MambaLCT)]

- **LMTrack:** Chenlong Xu, Bineng Zhong, Qihua Liang, Yaozong Zheng, Guorong Li, Shuxiang Song.<br />
  "Less is More: Token Context-aware Learning for Object Tracking." AAAI (2025).
  [[Paper](https://arxiv.org/abs/2501.00758)]
  
- **TemTrack:** Jinxia Xie, Bineng Zhong, Qihua Liang, Ning Li, Zhiyi Mo, Shuxiang Song.<br />
  "Robust Tracking via Mamba-based Context-aware Token Learning." AAAI (2025).
  [[Paper](https://arxiv.org/abs/2412.13611)]
  [[code](https://github.com/GXNU-ZhongLab/TemTrack)]

- **STTrack:** Xiantao Hu,Ying Tai,Xu zhao,Chen Zhao,Zhenyu  Zhang,Jun Li,Bineng Zhong,Jian Yang.<br />
  "Exploiting Multimodal Spatial-temporal Patterns for Video Object  Tracking." AAAI (2025).
  [[paper](https://arxiv.org/abs/2412.15691)] 
  [[code](https://github.com/NJU-PCALab/STTrack)]

- **SSTrack:** Zheng, Y., Zhong, B., Liang, Q., Li, N., & Song, S.<br />
  "Decoupled Spatio-Temporal Consistency Learning for Self-Supervised Tracking." AAAI (2025).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/33155)] 
  [[code](https://github.com/GXNU-ZhongLab/SSTrack)]

- **MIMTrack:** Wang, X., Nie, G., Meng, J., & Yan, Z.<br />
  "MIMTrack: In-Context Tracking via Masked Image Modeling." AAAI (2025).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/32860)]

- **AsymTrack:** Jiawen Zhu,Huayi Tang,Xin Chen,Xinying Wang,Dong  Wang,Huchuan Lu.<br />
  "Two-stream Beats One-stream: Asymmetric Siamese Network for  Efficient Visual Tracking." AAAI (2025).
  [[paper](https://arxiv.org/abs/2503.00516)]
  [[code](https://github.com/jiawen-zhu/AsymTrack)] 

- **LVPTrack:** Hongjing Wu,Siyuan Yao,Feng Huang,Shu  Wang,Linchao Zhang,Zhuoran Zheng,Wenqi Ren.<br />
  "LVPTrack: High Performance Domain Adaptive UAV Tracking with  Label Aligned Visual Prompt Tuning." AAAI (2025).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/32906)] 

- **AINet:** Andong Lu, Wanyu Wang, Chenglong Li, Jin Tang, Bin Luo.<br />
  "RGBT Tracking via All-layer Multimodal Interactions with Progressive Fusion Mamba." AAAI (2025).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/32618)] 

- **CAFormer:** Yun Xiao, Jiacong Zhao, Andong Lu, Chenglong Li, Bing Yin, Yin Lin, Cong Liu.<br />
  "Cross-modulated Attention Transformer for RGBT Tracking." AAAI (2025).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/32938)] 
  [[code](https://github.com/opacity-black/CAFormer)]

- **UAWTrack:** Yuxiang Yang, Hongjie Gu, Yingqi Deng, Zhekang Dong, Zhiwei He, Jing Zhang.<br />
  "UAWTrack: Universal 3D Single Object Tracking in Adverse Weather." AAAI (2025).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/33011)] 

### NeurIPS 2024

- **ChatTracker:** Yiming Sun, Fan Yu, Shaoxiang Chen, Yu Zhang, Junwei Huang, Chenhui Li, Yang Li, Changbo Wang.<br />
  "ChatTracker: Enhancing Visual Tracking Performance via Chatting with Multimodal Large Language Model." NeurIPS (2024).
  [[paper](https://arxiv.org/abs/2411.01756)] 

- **WebUOT-1M:** Chunhui Zhang, Li Liu, Guanjie Huang, Hao Wen, Xi Zhou, Yanfeng Wang.<br />
  "WebUOT-1M: Advancing Deep Underwater Object Tracking with A Million-Scale Benchmark." NeurIPS (2024).
  [[paper](https://arxiv.org/abs/2405.19818)] 
  [[code](https://github.com/983632847/Awesome-Multimodal-Object-Tracking)]

- **DeTrack:** Xinyu Zhou, Jinglun Li, Lingyi Hong, Kaixun Jiang, Pinxue Guo, Weifeng Ge, Wenqiang Zhang.<br />
  "DeTrack: In-model Latent Denoising Learning for Visual Object Tracking." NeurIPS (2024).
  [[paper](https://openreview.net/forum?id=ZJjuNF0olj)] 
  [[code]( )]

- **CSAM:** Tianlu Zhang, Kurt Debattista, Qiang Zhang, Guiguang Ding, Jungong Han.<br />
  "Revisiting Motion Information for RGB-Event Tracking with MOT Philosophy." NeurIPS (2024).
  [[paper](https://openreview.net/forum?id=bzGAELYOyL)] 
  [[code]( )]

- **DINTR:** Pha Nguyen, Ngan Le, Jackson Cothren, Alper Yilmaz, Khoa Luu.<br />
  "DINTR: Tracking via Diffusion-based Interpolation." NeurIPS (2024).
  [[paper](https://arxiv.org/abs/2410.10053)] 
  [[code]( )]

- **UAV3D:** Hui Ye, Rajshekhar Sunderraman, Shihao Ji.<br />
  "UAV3D: A Large-scale 3D Perception Benchmark for Unmanned Aerial  Vehicles." NeurIPS (2024).
  [[paper](https://arxiv.org/abs/2410.11125)] 
  [[code](https://huiyegit.github.io/UAV3D_Benchmark/)]
  
- **MemVLT:** Xiaokun Feng, Xuchen Li, Shiyu Hu, Dailing Zhang, Meiqi Wu, Xiaotang Chen, Kaiqi Huang.<br />
  "MemVLT: Vision-Language Tracking with Adaptive Memory-based Prompts." NeurIPS (2024).
  [[paper](https://openreview.net/forum?id=ZK1CZXKgG5)] 
  [[code](https://github.com/XiaokunFeng/MemVLT)]

- **CPDTrack:** Dailing Zhang, Shiyu Hu, Xiaokun Feng, Xuchen Li, Meiqi Wu, Kaiqi Huang.<br />
  "Beyond Accuracy: Tracking more like Human via Visual Search." NeurIPS (2024).
  [[paper](https://openreview.net/forum?id=LezAEImfoc)] 
  [[code](https://github.com/ZhangDailing8/CPDTrack)]



### ECCV 2024

- **Diff-Tracker:** Zhengbo Zhang, Li Xu, Duo Peng, Hossein Rahmani, Jun Liu.<br />
  "Diff-Tracker: Text-to-Image Diffusion Models are Unsupervised Trackers." ECCV (2024).
  [[paper](https://arxiv.org/abs/2407.08394)] 
  [[code]( )]

- **LoRAT:** Liting Lin, Heng Fan, Zhipeng Zhang, Yaowei Wang, Yong Xu, Haibin Ling.<br />
  "Tracking Meets LoRA: Faster Training, Larger Model, Stronger Performance." ECCV (2024).
  [[paper](https://arxiv.org/abs/2403.05231)] 
  [[code](https://github.com/LitingLin/LoRAT)]

- **VideoMamba:** Kunchang Li, Xinhao Li, Yi Wang, Yinan He, Yali Wang, Limin Wang, Yu Qiao.<br />
  "VideoMamba: State Space Model for Efficient Video Understanding." ECCV (2024).
  [[paper](https://arxiv.org/abs/2403.06977)] 
  [[code](https://huggingface.co/OpenGVLab/VideoMamba)]

- **DINO-Tracker:** Narek Tumanyan, Assaf Singer, Shai Bagon, Tali Dekel.<br />
  "DINO-Tracker: Taming DINO for Self-Supervised Point Tracking in a Single Video." ECCV (2024).
  [[paper](https://arxiv.org/abs/2403.14548v1)] 
  [[code](https://dino-tracker.github.io/)]

- **DecoMotion:** Rui Li, Dong Liu.<br />
  "Decomposition Betters Tracking Everything Everywhere." ECCV (2024).
  [[paper](https://arxiv.org/abs/2407.06531)] 
  [[code](https://github.com/qianduoduolr/DecoMotion)]

- **Elysium:** Han Wang, Yanjie Wang, Yongjie Ye, Yuxiang Nie, Can Huang.<br />
  "Elysium: Exploring Object-level Perception in Videos via MLLM." ECCV (2024).
  [[paper](https://arxiv.org/abs/2408.02049)] 
  [[code](https://github.com/Hon-Wong/Elysium)]
  
- **HVTrack:** Qiao Wu, Kun Sun, Pei An, Mathieu Salzmann, Yanning Zhang, Jiaqi Yang.<br />
  "3D Single-object Tracking in Point Clouds with High Temporal Variation." ECCV (2024).
  [[paper](https://arxiv.org/abs/2408.02049)] 
  [[code]( )]

- **AADN:** Zhewei Wu, Ruilong Yu, Qihe Liu, Shuying Cheng, Shilin Qiu, Shijie Zhou.<br />
  "Enhancing Tracking Robustness with Auxiliary Adversarial Defense Networks." ECCV (2024).
  [[paper](https://arxiv.org/abs/2402.17976)] 
  [[code](https://github.com/)]

  
### CVPR 2024

- **MASA:** Siyuan Li, Lei Ke, Martin Danelljan, Luigi Piccinelli, Mattia Segu, Luc Van Gool, Fisher Yu.<br />
  "Matching Anything by Segmenting Anything." CVPR (2024).
  [[paper](https://arxiv.org/abs/2406.04221)] 
  [[code](https://matchinganything.github.io/)]
  
- **OneTracker:** Lingyi Hong, Shilin Yan, Renrui Zhang, Wanyun Li, Xinyu Zhou, Pinxue Guo, Kaixun Jiang, Yiting Cheng, Jinglun Li, Zhaoyu Chen, Wenqiang Zhang.<br />
  "OneTracker: Unifying Visual Object Tracking with Foundation Models and Efficient Tuning." CVPR (2024).
  [[paper](https://arxiv.org/abs/2403.09634)] 
  [[code](https://)]

- **ARTrackV2:** Yifan Bai, Zeyang Zhao, Yihong Gong, Xing Wei.<br />
  "ARTrackV2: Prompting Autoregressive Tracker Where to Look and How to Describe." CVPR (2024).
  [[paper](https://arxiv.org/abs/2312.17133)]
  [[code](https://github.com/AlexDotHam/ARTrackV2)]
  [[project](https://artrackv2.github.io/)]

- **DiffusionTrack:** Fei Xie, Zhongdao Wang, Chao Ma.<br />
  "DiffusionTrack: Point Set Diffusion Model for Visual Object Tracking." CVPR (2024).
  [[paper](https://arxiv.org/)] 
  [[code](https://)]

- **RTracker:** Yuqing Huang, Xin Li, Zikun Zhou, Yaowei Wang, Zhenyu He, Ming-Hsuan Yang.<br />
  "RTracker: Recoverable Tracking via PN Tree Structured Memory." CVPR (2024).
  [[paper](https://arxiv.org/)] 
  [[code](https://)]

- **NetTrack:** Guangze Zheng, Shijie Lin, Haobo Zuo, Changhong Fu, Jia Pan.<br />
  "NetTrack: Tracking Highly Dynamic Objects with a Net." CVPR (2024).
  [[paper](https://arxiv.org/abs/2403.11186)] 
  [[code](https://george-zhuang.github.io/nettrack/)]

- **Un-Track:** Zongwei Wu, Jilai Zheng, Xiangxuan Ren, Florin-Alexandru Vasluianu, Chao Ma, Danda Pani Paudel, Luc Van Gool, Radu Timofte.<br />
  "Single-Model and Any-Modality for Video Object Tracking." CVPR (2024).
  [[paper](https://arxiv.org/abs/2311.15851)] 
  [[code](https://github.com/Zongwei97/UnTrack)]

- **HIPTrack:** Wenrui Cai, Qingjie Liu, Yunhong Wang.<br />
  "HIPTrack: Visual Tracking with Historical Prompts." CVPR (2024).
  [[paper](https://arxiv.org/abs/2311.02072)] 
  [[code](https://xxx)]

- **AQATrack:** Jinxia Xie, Bineng Zhong, Zhiyi Mo, Shengping Zhang, Liangtao Shi, Shuxiang Song, Rongrong Ji.<br />
  "Autoregressive Queries for Adaptive Tracking with Spatio-Temporal Transformers." CVPR (2024).
  [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Xie_Autoregressive_Queries_for_Adaptive_Tracking_with_Spatio-Temporal_Transformers_CVPR_2024_paper.html)] 
  [[code](https://github.com/GXNU-ZhongLab/AQATrack)]

- **MMA:** Lingxiao Yang, Ru-Yuan Zhang, Yanchen Wang, Xiaohua Xie.<br />
  "MMA: Multi-Modal Adapter for Vision-Language Models." CVPR (2024).
  [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Yang_MMA_Multi-Modal_Adapter_for_Vision-Language_Models_CVPR_2024_paper.html)] 
  [[code](https://github.com/ZjjConan/Multi-Modal-Adapter)]

- **SDSTrack:** Xiaojun Hou, Jiazheng Xing, Yijie Qian, Yaowei Guo, Shuo Xin, Junhao Chen, Kai Tang, Mengmeng Wang, Zhengkai Jiang, Liang Liu, Yong Liu.<br />
  "SDSTrack: Self-Distillation Symmetric Adapter Learning for Multi-Modal Visual Object Tracking." CVPR (2024).
  [[paper](https://arxiv.org/)] 
  [[code](https://)]

- **HDETrack:** Xiao Wang, Shiao Wang, Chuanming Tang, Lin Zhu, Bo Jiang, Yonghong Tian, Jin Tang.<br />
  "Event Stream-based Visual Object Tracking: A High-Resolution Benchmark Dataset and A Novel Baseline." CVPR (2024).
  [[paper](https://arxiv.org/abs/2309.14611)] 
  [[code](https://github.com/Event-AHU/EventVOT_Benchmark)]

- **CAI:** Yanyan Shao, Shuting He, Qi Ye, Yuchao Feng, Wenhan Luo, Jiming Chen.<br />
  "Context-Aware Integration of Language and Visual References for Natural Language Tracking." CVPR (2024).
  [[paper](https://arxiv.org/)] 
  [[code](https://)]

- **ResampleTrack:** Xuhong Ren, Jianlang Chen, Yue Cao, Wanli Xue, Qing Guo, Lei Ma, Jianjun Zhao, Shenyong Chen.<br />
  "ResampleTrack: Online Resampling for Adversarially Robust Visual Tracking." CVPR (2024).
  [[paper](https://openaccess.thecvf.com/content/CVPR2024W/AdvML/html/Ren_ResampleTrack_Online_Resampling_for_Adversarially_Robust_Visual_Tracking_CVPRW_2024_paper.html)] 
  [[code]( )]
  

### WACV 2024

- **ContrasTR:** Pierre-François De Plaen, Nicola Marinello, Marc Proesmans, Tinne Tuytelaars, Luc Van Gool.<br />
  "Contrastive Learning for Multi-Object Tracking With Transformers." WACV (2024).
  [[paper](https://openaccess.thecvf.com/content/WACV2024/papers/De_Plaen_Contrastive_Learning_for_Multi-Object_Tracking_With_Transformers_WACV_2024_paper.pdf)] 
  [[code]()]

- **LaGOT:** Christoph Mayer, Martin Danelljan, Ming-Hsuan Yang, Vittorio Ferrari, Luc Van Gool, Alina Kuznetsova.<br />
  "Beyond SOT: It's Time to Track Multiple Generic Objects at Once." WACV (2024).
  [[paper](https://arxiv.org/abs/2212.11920)] 
  [[code](https://github.com/visionml/pytracking)]

- **SMAT:** Goutam Yelluru Gopal, Maria A. Amer.<br />
  "Separable Self and Mixed Attention Transformers for Efficient Object Tracking." WACV (2024).
  [[paper](https://arxiv.org/abs/2309.03979)] 
  [[code](https://github.com/goutamyg/SMAT)]
  
- **DATr:** Jie Zhao, Johan Edstedt, Michael Felsberg, Dong Wang, Huchuan Lu.<br />
  "Leveraging the Power of Data Augmentation for Transformer-based Tracking." WACV (2024).
  [[paper](https://arxiv.org/abs/2309.08264)] 
  [[code](https://github.com/zj5559/DATr)]
  
### AAAI 2024

- **GMMT:** Zhangyong Tang, Tianyang Xu, Xuefeng Zhu, Xiao-Jun Wu, Josef Kittler.<br />
  "Generative-based Fusion Mechanism for Multi-Modal Tracking." AAAI (2024).
  [[paper](https://arxiv.org/abs/2309.01728)] 
  [[code](https://github.com/Zhangyong-Tang/GMMT)]

- **ODTrack:** Yaozong Zheng, Bineng Zhong, Qihua Liang, Zhiyi Mo, Shengping Zhang, Xianxian Li.<br />
  "ODTrack: Online Dense Temporal Token Learning for Visual Tracking." AAAI (2024).
  [[paper](https://arxiv.org/abs/2401.01686)] 
  [[code](https://github.com/GXNU-ZhongLab/ODTrack)]

 - **EVPTrack:** Liangtao Shi, Bineng Zhong, Qihua Liang, Ning Li, Shengping Zhang, Xianxian Li.<br />
  "Explicit Visual Prompts for Visual Object Tracking." AAAI (2024).
  [[paper](https://arxiv.org/abs/2401.03142)] 
  [[code](https://github.com/GXNU-ZhongLab/EVPTrack)] 
  
- **BAT:** Bing Cao, Junliang Guo, Pengfei Zhu, Qinghua Hu.<br />
  "Bi-directional Adapter for Multimodal Tracking." AAAI (2024).
  [[paper](https://arxiv.org/abs/2312.10611)] 
  [[code](https://github.com/SparkTempest/BAT)]

- **TATrack:** Hongyu Wang, Xiaotao Liu, Yifan Li, Meng Sun, Dian Yuan, Jing Liu.<br />
  "Temporal Adaptive RGBT Tracking with Modality Prompt." AAAI (2024).
  [[paper](https://arxiv.org/abs/2401.01244)] 
  [[code]()]

- **Hybrid-SORT:** Mingzhan Yang, Guangxin Han, Bin Yan, Wenhua Zhang, Jinqing Qi, Huchuan Lu, Dong Wang.<br />
  "Hybrid-SORT: Weak Cues Matter for Online Multi-Object Tracking." AAAI (2024).
  [[paper](https://arxiv.org/abs/2308.00783)] 
  [[code](https://github.com/ymzis69/HybirdSORT)]

- Md Maklachur Rahman.<br />
  "Target Focused Shallow Transformer Framework for Efficient Visual Tracking." AAAI (2024).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/30405)] 

- **STCFormer:** Hu, K., Yang, W., Huang, W., Zhou, X., Cao, M., Ren, J., & Tan, H.<br />
  "Sequential Fusion Based Multi-Granularity Consistency for Space-Time Transformer Tracking." AAAI (2024).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/29145)] 

### ArXiv-2024

- **SeqTrack3D:** Yu Lin, Zhiheng Li, Yubo Cui, Zheng Fang.<br />
  "SeqTrack3D: Exploring Sequence Information for Robust 3D Point Cloud Tracking." ICRA (2024).
  [[paper](https://arxiv.org/abs/2402.16249)] 
  [[code](https://github.com/aron-lin/seqtrack3d)]
  
- **VAT:** Guangtong Zhang, Qihua Liang, Zhiyi Mo, Ning Li, Bineng Zhong.<br />
  "Visual Adapt For RGBD Tracking." ICASSP (2024).
  [[paper](https://arxiv.org )] 
  [[code](https://github.com/ )]

- **UVLTrack:** Yinchao Ma, Yuyang Tang, Wenfei Yang, Tianzhu Zhang, Jinpeng Zhang, Mengxue Kang.<br />
  "Unifying Visual and Vision-Language Tracking via Contrastive Learning." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2401.11228)] 
  [[code](https://github.com/OpenSpaceAI/UVLTrack)]

- **SuperSBT:** Fei Xie, Wankou Yang, Chunyu Wang, Lei Chu, Yue Cao, Chao Ma, Wenjun Zeng.<br />
  "Correlation-Embedded Transformer Tracking: A Single-Branch Framework." ArXiv (2024).
  [[paper](https://arxiv.org/abs/2401.12743)] 
  [[code](https://github.com/phiphiphi31/SBT)]

- Yassir Zardoua, Abdes-samed Bernoussi, Mina Amharref & Mustapha Ouardouz .<br />
  "Adapting a Modern Siamese Framework for 360 Video Object Tracking." icSoftComp (2024).
  [[paper](https://link.springer.com/book/10.1007/978-3-031-88039-1)] 

### NeurIPS 2023

- **MixFormerV2:** Yutao Cui, Tianhui Song, Gangshan Wu, Limin Wang.<br />
  "MixFormerV2: Efficient Fully Transformer Tracking." NeurIPS (2023).
  [[paper](https://arxiv.org/abs/2305.15896)] 
  [[code](https://github.com/MCG-NJU/MixFormerV2)]
  
- **ZoomTrack:** Yutong Kou, Jin Gao, Bing Li, Gang Wang, Weiming Hu, Yizheng Wang, Liang Li.<br />
  "ZoomTrack: Target-aware Non-uniform Resizing for Efficient Visual Tracking." NeurIPS (2023).
  [[paper](https://arxiv.org/abs/2310.10071)] 
  [[code](https://github.com/Kou-99/ZoomTrack)]

- **Type-to-Track:** Pha Nguyen, Kha Gia Quach, Kris Kitani, Khoa Luu.<br />
  "Type-to-Track: Retrieve Any Object via Prompt-based Tracking." NeurIPS (2023).
  [[paper](https://arxiv.org/abs/2305.13495)] 
  [[code](https://uark-cviu.github.io/Type-to-Track)]

- **MGIT:** Shiyu Hu, Dailin Zhang, Meiqi Wu, Xiaokun Feng, Xuchen Li, Xin Zhao, Kaiqi Huang.<br />
  "A Multi-modal Global Instance Tracking Benchmark (MGIT): Better Locating Target in Complex Spatio-temporal and Causal Relationship." NeurIPS (2023).
  [[paper](https://arxiv.org/abs/xxxxx.xx)] 
  [[code](http://videocube.aitestunion.com/)]


### ICCV 2023

- **VTDNet:** Thomas E. Huang, Yifan Liu, Luc Van Gool, Fisher Yu.<br />
  "Video Task Decathlon: Unifying Image and Video Tasks in Autonomous Driving." ICCV (2023).
  [[paper](https://arxiv.org/abs/2309.04422)] 
  [[code](https://www.vis.xyz/pub/vtd)]
  
- **HiT:** Ben Kang, Xin Chen, Dong Wang, Houwen Peng, Huchuan Lu.<br />
  "Exploring Lightweight Hierarchical Vision Transformers for Efficient Visual Tracking." ICCV (2023).
  [[paper](https://arxiv.org/abs/2308.06904)] 
  [[code](https://github.com/kangben258/HiT)]

- **ROMTrack:** Yidong Cai, Jie Liu, Jie Tang, Gangshan Wu.<br />
  "Robust Object Modeling for Visual Tracking." ICCV (2023).
  [[paper](https://arxiv.org/abs/2308.05140)] 
  [[code](https://github.com/dawnyc/ROMTrack)]

- **F-BDMTrack:** Dawei Yang, Jianfeng He, Yinchao Ma, Qianjin Yu, Tianzhu Zhang.<br />
  "Foreground-Background Distribution Modeling Transformer for Visual Object Tracking." ICCV (2023).
  [[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Foreground-Background_Distribution_Modeling_Transformer_for_Visual_Object_Tracking_ICCV_2023_paper.pdf)] 
  [[code]()]

- **MITS:** Yuanyou Xu, Zongxin Yang, Yi Yang.<br />
  "Integrating Boxes and Masks: A Multi-Object Framework for Unified Visual Tracking and Segmentation." ICCV (2023).
  [[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Integrating_Boxes_and_Masks_A_Multi-Object_Framework_for_Unified_Visual_ICCV_2023_paper.pdf)] 
  [[code](https://github.com/yoxu515/MITS)]

- **Aba-ViTrack:** Shuiwang Li, Yangxiang Yang, Dan Zeng, Xucheng Wang.<br />
  "Adaptive and Background-Aware Vision Transformer for Real-Time UAV Tracking." ICCV (2023).
  [[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Adaptive_and_Background-Aware_Vision_Transformer_for_Real-Time_UAV_Tracking_ICCV_2023_paper.pdf)] 
  [[code](https://github.com/xyyang317/Aba-ViTrack)]
  
- **Omnimotion:** Qianqian Wang, Yen-Yu Chang, Ruojin Cai, Zhengqi Li, Bharath Hariharan, Aleksander Holynski, Noah Snavely.<br />
  "Tracking Everything Everywhere All at Once." ICCV (2023).
  [[paper](https://arxiv.org/abs/2306.05422)] 
  [[code](https://omnimotion.github.io/)]
  
- **DEVA:** Ho Kei Cheng, Seoung Wug Oh, Brian Price, Alexander Schwing, Joon-Young Lee.<br />
  "Tracking Anything with Decoupled Video Segmentation." ICCV (2023).
  [[paper](https://arxiv.org/abs/2309.03903)] 
  [[code](https://hkchengrex.github.io/Tracking-Anything-with-DEVA)]

- **CiteTracker:** Xin Li, Yuqing Huang, Zhenyu He, Yaowei Wang, Huchuan Lu, Ming-Hsuan Yang.<br />
  "CiteTracker: Correlating Image and Text for Visual Tracking." ICCV (2023).
  [[paper](https://arxiv.org/abs/2308.11322)] 
  [[code](https://github.com/xinli/citetracker)]

- **DecoupleTNL:** Ding Ma, Xiangqian Wu.<br />
  "Tracking by Natural Language Specification with Long Short-term Context Decoupling." ICCV (2023).
  [[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Tracking_by_Natural_Language_Specification_with_Long_Short-term_Context_Decoupling_ICCV_2023_paper.pdf)] 
  [[code]()]
  
- **PVT++:** Bowen Li, Ziyuan Huang, Junjie Ye, Yiming Li, Sebastian Scherer, Hang Zhao, Changhong Fu.<br />
  "PVT++: A Simple End-to-End Latency-Aware Visual Tracking Framework." ICCV (2023).
  [[paper](https://arxiv.org/abs/2211.11629)] 
  [[code](https://github.com/Jaraxxus-Me/PVT_pp)]

- **SyncTrack:** Teli Ma, Mengmeng Wang, Jimin Xiao, Huifeng Wu, Yong Liu.<br />
  "Synchronize Feature Extracting and Matching: A Single Branch Framework for 3D Object Tracking." ICCV (2023).
  [[paper](https://arxiv.org/abs/2308.12549)] 
  [[code](https://xxxxx)]
  
- **360VOT:** Huajian Huang, Yinzhe Xu, Yingshu Chen, Sai-Kit Yeung.<br />
  "360VOT: A New Benchmark Dataset for Omnidirectional Visual Object Tracking." ICCV (2023).
  [[paper](https://arxiv.org/abs/2307.14630)] 
  [[code](https://360vot.hkustvgd.com/)]

- **PlanarTrack:** Xinran Liu, Xiaoqiong Liu, Ziruo Yi, Xin Zhou, Thanh Le, Libo Zhang, Yan Huang, Qing Yang, Heng Fan.<br />
  "PlanarTrack: A Large-scale Challenging Benchmark for Planar Object Tracking." ICCV (2023).
  [[paper](https://arxiv.org/abs/2303.07625)] 
  [[code](https://hengfan2010.github.io/projects/PlanarTrack/)]
       
### CVPR 2023

- **X-Decoder:** Xueyan Zou, Zi-Yi Dou, Jianwei Yang, Zhe Gan, Linjie Li, Chunyuan Li, Xiyang Dai, Harkirat Behl, Jianfeng Wang, Lu Yuan, Nanyun Peng, Lijuan Wang, Yong Jae Lee, Jianfeng Gao.<br />
  "Generalized Decoding for Pixel, Image, and Language." CVPR (2023).
  [[paper](https://arxiv.org/abs/2212.11270)] 
  [[code](https://x-decoder-vl.github.io/)]
  
- **UNINEXT:** Bin Yan, Yi Jiang, Jiannan Wu, Dong Wang, Ping Luo, Zuhuan Yuan, Huchuan Lu.<br />
  "Universial Instance Perception as Object Discovery and Retrieval." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.06674)] 
  [[code](https://github.com/MasterBin-IIAU/UNINEXT)]
  
- **OmniTracker:** Junke Wang, Dongdong Chen, Zuxuan Wu, Chong Luo, Xiyang Dai, Lu Yuan, Yu-Gang Jiang.<br />
  "OmniTracker: Unifying Object Tracking by Tracking-with-Detection." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.12079)] 
  [[code](https://github.com/)]

- **SUSHI:** Orcun Cetintas, Guillem Brasó, Laura Leal-Taixé.<br />
  "Unifying Short and Long-Term Tracking with Graph Hierarchies." CVPR (2023).
  [[paper](https://arxiv.org/abs/2212.03038)] 
  [[code](https://github.com/dvl-tum/SUSHI)]
  
- **DropMAE:** Qiangqiang Wu, Tianyu Yang, Ziquan Liu, Baoyuan Wu, Ying Shan, Antoni B. Chan.<br />
  "DropMAE: Masked Autoencoders with Spatial-Attention Dropout for Tracking Tasks." CVPR (2023).
  [[paper](https://arxiv.org/abs/2304.00571)] 
  [[code](https://github.com/jimmy-dq/DropMAE)]
  
- **VideoTrack:** Fei Xie, Lei Chu, Jiahao Li, Yan Lu, Chao Ma.<br />
  "VideoTrack: Learning to Track Objects via Video Transformer." CVPR (2023).
  [[paper](https://arxiv.org/abs/x)] 
  [[code](https://github.com/phiphiphi31/VideoTrack)]
  
- **SwinV2:** Zhenda Xie, Zigang Geng, Jingcheng Hu, Zheng Zhang, Han Hu, Yue Cao.<br />
  "Revealing the Dark Secrets of Masked Image Modeling." CVPR (2023).
  [[paper](https://arxiv.org/abs/2205.13543)] 
  [[code](https://github.com/SwinTransformer/MIM-Depth-Estimation)]
  
- **ViPT:** Jiawen Zhu, Simiao Lai, Xin Chen, Dong Wang, Huchuan Lu.<br />
  "Visual Prompt Multi-Modal Tracking." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.10826)] 
  [[code](https://github.com/jiawen-zhu/ViPT)]
  
 - **JointNLT:** Li Zhou, Zikun Zhou, Kaige Mao, Zhenyu He.<br />
  "Joint Visual Grounding and Tracking with Natural Language Specification." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.12027)] 
  [[code](https://github.com/lizhou-cs/JointNLT)]
  
 - **ARKitTrack:** Haojie Zhao, Junsong Chen, Lijun Wang, Huchuan Lu.<br />
  "ARKitTrack: A New Diverse Dataset for Tracking Using Mobile RGB-D Data." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.13885)] 
  [[code](https://arkittrack.github.io/)]
  
 - **GRM:** Shenyuan Gao, Chunluan Zhou, Jun Zhang.<br />
  "Generalized Relation Modeling for Transformer Tracking." CVPR (2023).
  [[paper](https://arxiv.org/pdf/2303.16580v1.pdf)] 
  [[code](https://github.com/Little-Podi/GRM)]
  
 - **ARTrack:** Xing Wei, Yifan Bai, Yongchao Zheng, Dahu Shi, Yihong Gong.<br />
  "Autoregressive Visual Tracking." CVPR (2023).
  [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Wei_Autoregressive_Visual_Tracking_CVPR_2023_paper.html)] 
  [[code](https://github.com/MIV-XJTU/ARTrack)]
  
 - **MAT:** Haojie Zhao, Dong Wang, Huchuan Lu.<br />
  "Representation Learning for Visual Object Tracking by Masked Appearance Transfer." CVPR (2023).
  [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Zhao_Representation_Learning_for_Visual_Object_Tracking_by_Masked_Appearance_Transfer_CVPR_2023_paper.html)] 
  [[code](https://github.com/difhnp/MAT)]
  
 - **EMT:** Jinyu Yang, Shang Gao, Zhe Li, Feng Zheng, Aleš Leonardis.<br />
  "Resource-Efficient RGBD Aerial Tracking." CVPR (2023).
  [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Yang_Resource-Efficient_RGBD_Aerial_Tracking_CVPR_2023_paper.html)] 
  [[code](https://github.com/yjybuaa/RGBDAerialTracking)]
  
 - **TBSI:** Tianrui Hui, Zizheng Xun, Fengguang Peng, Junshi Huang, Xiaoming Wei, Xiaolin Wei, Jiao Dai, Jizhong Han, Si Liu.<br />
  "Bridging Search Region Interaction With Template for RGB-T Tracking." CVPR (2023).
  [[paper](https://openaccess.thecvf.com/content/CVPR2023/html/Hui_Bridging_Search_Region_Interaction_With_Template_for_RGB-T_Tracking_CVPR_2023_paper.html)] 
  [[code](https://github.com/RyanHTR/TBSI)]
  
 - **VisTracker:** Xianghui Xie, Bharat Lal Bhatnagar, Gerard Pons-Moll.<br />
  "Visibility Aware Human-Object Interaction Tracking from Single RGB Camera." CVPR (2023).
  [[paper](https://arxiv.org/abs/2303.16479v1)] 
  [[code](https://virtualhumans.mpi-inf.mpg.de/VisTracker/)]
  
 - **OVTrack:** Siyuan Li, Tobias Fischer, Lei Ke, Henghui Ding, Martin Danelljan, Fisher Yu.<br />
  "OVTrack: Open-Vocabulary Multiple Object Tracking." CVPR (2023).
  [[paper](https://arxiv.org/abs/2304.08408)] 
  [[code](https://www.vis.xyz/pub/ovtrack/)]
  
 - **SeqTrack:** Xin Chen, Houwen Peng, Dong Wang, Huchuan Lu, Han Hu.<br />
  "SeqTrack: Sequence to Sequence Learning for Visual Object Tracking." CVPR (2023).
  [[paper](https://arxiv.org/abs/2304.14394)] 
  [[code](https://github.com/microsoft/VideoX)]
  
 - **ImageBind:** Rohit Girdhar, Alaaeldin El-Nouby, Zhuang Liu, Mannat Singh, Kalyan Vasudev Alwala, Armand Joulin, Ishan Misra.<br />
  "IMAGEBIND: One Embedding Space To Bind Them All." CVPR (2023).
  [[paper](https://arxiv.org/abs/2305.05665)] 
  [[code](https://github.com/facebookresearch/ImageBind)]
  
 - **TCOW:** Basile Van Hoorick, Pavel Tokmakov, Simon Stent, Jie Li, Carl Vondrick.<br />
  "Tracking through Containers and Occluders in the Wild." CVPR (2023).
  [[paper](https://arxiv.org/abs/2305.03052)] 
  [[code](https://tcow.cs.columbia.edu/)]
  

### ArXiv 2023

- **UTrack:** Jie Gao, Bineng Zhong, Yan Chen.<br />
  "Unambiguous Object Tracking by Exploiting Target Cues." ACM MM (2023).
  [[paper](https://dl.acm.org/doi/10.1145/3581783.3612240)] 
  [[code]()]

- **UPVPT:** Guangtong Zhang, Qihua Liang, Ning Li, Zhiyi Mo, Bineng Zhong.<br />
  "Robust Tracking via Unifying Pretrain-Finetuning and Visual Prompt Tuning." ACM MMAsia (2023).
  [[paper](https://dl.acm.org/doi/10.1145/3595916.3626410)] 
  [[code]()]

- **TAO-Amodal:** Cheng-Yen Hsieh, Tarasha Khurana, Achal Dave, Deva Ramanan.<br />
  "Tracking Any Object Amodally." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2312.12433)] 
  [[code](https://tao-amodal.github.io/)]

- **HQTrack:** Jiawen Zhu, Zhenyu Chen, Zeqi Hao, Shijie Chang, Lu Zhang, Dong Wang, Huchuan Lu, Bin Luo, Jun-Yan He, Jin-Peng Lan, Hanyuan Chen, Chenyang Li.<br />
  "Tracking Anything in High Quality." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2307.13974)] 
  [[code](https://github.com/jiawen-zhu/HQTrack)]

- **MMTrack:** Yaozong Zheng, Bineng Zhong, Qihua Liang, Guorong Li, Rongrong Ji, Xianxian Li.<br />
  "Towards Unified Token Learning for Vision-Language Tracking." TCSVT (2023).
  [[paper](https://arxiv.org/abs/2308.14103)] 
  [[code](https://github.com/Azong-HQU/MMTrack)]

- **OVLM:** Huanlong Zhang, Jingchao Wang, Jianwei Zhang, Tianzhu Zhang, Bineng Zhong.<br />
  "One-stream Vision-Language Memory Network for Object Tracking." TMM (2023).
  [[paper](https://ieeexplore.ieee.org/document/10149530)] 
  [[code]( )]

- **All-in-One:** Chunhui Zhang, Xin Sun, Li Liu, Yiqian Yang, Qiong Liu, Xi Zhou, Yanfeng Wang.<br />
  "All in One: Exploring Unified Vision-Language Tracking with Multi-Modal Alignment." ACM MM (2023).
  [[paper](https://arxiv.org/abs/2307.03373)] 
  [[code]( )]
  
- **MPLT:** Yang Luo, Xiqing Guo, Hui Feng, Lei Ao.<br />
  "RGB-T Tracking via Multi-Modal Mutual Prompt Learning." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2308.16386)] 
  [[code](https://github.com/HusterYoung/MPLT)]
  
- **DCPT:** Jiawen Zhu, Huayi Tang, Zhi-Qi Cheng, Jun-Yan He, Bin Luo, Shihao Qiu, Shengming Li, Huchuan Lu.<br />
  "DCPT: Darkness Clue-Prompted Tracking in Nighttime UAVs." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2309.10491)] 
  [[code](https://xxx)]

- **SRT:** Tianpeng Liu, Jing Li, Jia Wu, Lefei Zhang, Jun Chang, Jun Wan, Lezhi Lian.<br />
  "Tracking with Saliency Region Transformer." TIP (2023).
  [[paper](https://ieeexplore.ieee.org/document/10359476)] 
  [[code](https://github.xxxxx)]

- **TATrans:** Pujian Lai, Meili Zhang, Gong Cheng, Shengyang Li, Xiankai Huang, Junwei Han.<br />
  "Target-aware Transformer for Satellite Video Object Tracking." TGRS (2023).
  [[paper](https://ieeexplore.ieee.org/abstract/document/10342836)] 
  [[code](https://github.com/laybebe/TATrans_SVOT)]

- **STRtrack:** Shaochuan Zhao, Tianyang Xu, Xiaojun Wu, Josef Kittler.<br />
  "A Spatio-Temporal Robust Tracker with Spatial-Channel Transformer and Jitter Suppression." IJCV (2023).
  [[paper](https://link.springer.com/article/10.1007/s11263-023-01902-x)] 
  [[code](https://xxx)]

- **CoTracker:** Nikita Karaev, Ignacio Rocco, Benjamin Graham, Natalia Neverova, Andrea Vedaldi, Christian Rupprecht.<br />
  "CoTracker: It is Better to Track Together." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2307.07635)] 
  [[code](https://co-tracker.github.io/)]
  
- **LiteTrack:** Qingmao Wei, Bi Zeng, Jianqi Liu, Li He, Guotian Zeng.<br />
  "LiteTrack: Layer Pruning with Asynchronous Feature Extraction for Lightweight and Efficient Visual Tracking." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2309.09249)] 
  [[code](https://github.com/TsingWei/LiteTrack)]
  
- **LightFC:** Li Yunfeng, Wang Bo, Li Ye, Liu Zhuoyan, Wu Xueyi.<br />
  "Lightweight Full-Convolutional Siamese Tracker." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2310.05392)] 
  [[code](https://github.com/LiYunfengLYF/LightFC)]

- **DETRrack:** Qingmao Wei, Bi Zeng, Guotian Zeng.<br />
  "Efficient Training for Visual Tracking with Deformable Transformer." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2309.02676)] 
  [[code](https:xxx)]

- **JN:** Qingmao Wei, Bi Zeng, Guotian Zeng.<br />
  "Towards Efficient Training with Negative Samples in Visual Tracking." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2309.02903)] 
  [[code](hxx)]

- **COHA:** Zhiyu Zhu, Junhui Hou, Dapeng Oliver Wu.<br />
  "Cross-modal Orthogonal High-rank Augmentation for RGB-Event Transformer-trackers." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2307.04129)] 
  [[code](https:/xx)]
  
- **SparseTrack:** Zelin Liu, Xinggang Wang, Cheng Wang, Wenyu Liu, Xiang Bai.<br />
  "SparseTrack: Multi-Object Tracking by Performing Scene Decomposition based on Pseudo-Depth." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2306.05238)] 
  [[code](https://github.com/hustvl/SparseTrack)]
    
- **TransSOT:** Janani Thangavel, Thanikasalam Kokul, Amirthalingam Ramanan, Subha Fernando.<br />
  "Transformers in Single Object Tracking: An Experimental Survey." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2302.11867)] 
  [[code]()]
  
- **ProFormer:** Yabin Zhu, Chenglong Li, Xiao Wang, Jin Tang, Zhixiang Huang.<br />
  "RGBT Tracking via Progressive Fusion Transformer with Dynamically Guided Learning." ArXiv (2023).
  [[paper](https://arxiv.org/abs/2303.14778)] 
  [[code]()]

- **SOTVerse:** Shiyu Hu, Xin Zhao, Kaiqi Huang.<br />
  "SOTVerse: A User-defined Task Space of Single Object Tracking." IJCV (2023).
  [[paper](https://arxiv.org/abs/2204.07414)] 
  [[code](http://metaverse.aitestunion.com/sotverse)]

- **TSMTrack:** Chuanming Tang, Qintao Hu, Gaofan Zhou, Jinzhen Yao, Jianlin Zhang, Yongmei Huang, Qixiang Ye.<br />
  "Transformer Sub-Patch Matching for High-Performance Visual Object Tracking." TITS (2023).
  [[paper](https://ieeexplore.ieee.org/document/10101686)] 
  [[code](https:/xx)]

- **TADS:** Xin Li, Wenjie Pei, Yaowei Wang, Zhenyu He, Huchuan Lu, Ming-Hsuan Yang.<br />
  "Self-Supervised Tracking via Target-Aware Data Synthesis." TNNLS (2023).
  [[paper](https://ieeexplore.ieee.org/document/10004981)] 
  [[code]()]
  

### IJCAI 2023

- **OSP2B:** Jiahao Nie, Zhiwei He, Yuxiang Yang, Zhengyi Bao, Mingyu Gao, Jing Zhang.<br />
  "OSP2B: One-Stage Point-to-Box Network for 3D Siamese Tracking." IJCAI (2023).
  [[paper](https://arxiv.org/abs/2304.11584)] 
  [[code](https://github.com/HaozheQi/P2B)]
  
  
### WACV 2023

- **MVT:** Goutam Yelluru Gopal, Maria A. Amer.<br />
  "Mobile Vision Transformer-based Visual Object Tracking." BMVC (2023).
  [[paper](https://arxiv.org/abs/2309.05829)] 
  [[code](https://github.com/goutamyg/MVT)]
  
- **E.T.Track:** Philippe Blatter, Menelaos Kanakis, Martin Danelljan, Luc Van Gool.<br />
  "Efficient Visual Tracking with Exemplar Transformers." WACV (2023).
  [[paper](https://arxiv.org/abs/2112.09686)] 
  [[code](https://github.com/pblatter/ettrack)]
  

### AAAI 2023

- **CTTrack:** Zikai Song, Run Luo, Junqing Yu, Yi-Ping Phoebe Chen, Wei Yang.<br />
  "Compact Transformer Tracker with Correlative Masked Modeling." AAAI (2023).
  [[paper](https://arxiv.org/abs/2301.10938)] 
  [[code](https://github.com/HUSTDML/CTTrack)]
  
- **TATrack:** Kaijie He, Canlong Zhang, Sheng Xie, Zhixin Li, Zhiwen Wang.<br />
  "Target-Aware Tracking with Long-term Context Attention." AAAI (2023).
  [[paper](https://arxiv.org/abs/2302.13840)] 
  [[code](https://github.com/hekaijie123/TATrack)]
  
- **RGBD1K:** Xue-Feng Zhu, Tianyang Xu, Zhangyong Tang, Zucheng Wu, Haodong Liu, Xiao Yang, Xiao-Jun Wu, Josef Kittler.<br />
  "RGBD1K: A Large-scale Dataset and Benchmark for RGB-D Object Tracking." AAAI (2023).
  [[paper](https://arxiv.org/abs/2208.09787)] 
  [[code](https://github.com/xuefeng-zhu5/RGBD1K)]

- **GdaTFT:** Yun Liang; Qiaoqiao Li; Fumian Long.<br />
  "Global Dilated Attention and Target Focusing Network for Robust Tracking." AAAI (2023).
  [[paper](https://underline.io/lecture/69278-global-dilated-attention-and-target-focusing-network-for-robust-tracking)] 
  [[code](https://github.com/)]
  
- **GLT-T:** Jiahao Nie, Zhiwei He, Yuxiang Yang, Mingyu Gao, Jing Zhang.<br />
  "GLT-T: Global-Local Transformer Voting for 3D Single Object Tracking in Point Clouds." AAAI (2023).
  [[paper](https://arxiv.org/abs/2211.10927)] 
  [[extended](https://arxiv.org/abs/2304.00242)] 
  [[code](https://github.com/haooozi/GLT-T)]
  
- **RSPT:** Fangwei Zhong, Xiao Bi, Yudi Zhang, Wei Zhang, Yizhou Wang.<br />
  "RSPT: Reconstruct Surroundings and Predict Trajectories for Generalizable Active Object Tracking." AAAI (2023).
  [[paper](https://arxiv.org/abs/2304.03623)] 
  [[code](https://sites.google.com/view/aot-rspt)]
  
### NeurIPS 2022

- **SwinTrack:** Liting Lin, Heng Fan, Yong Xu, Haibin Ling.<br />
  "SwinTrack: A Simple and Strong Baseline for Transformer Tracking." NeurIPS (2022).
  [[paper](https://arxiv.org/abs/2112.00995)] 
  [[code](https://github.com/LitingLin/SwinTrack)]
  
- **VLTrack:** Mingzhe Guo, Zhipeng Zhang, Heng Fan, Liping Jing.<br />
  "Divert More Attention to Vision-Language Tracking." NeurIPS (2022).
  [[paper](https://arxiv.org/abs/2207.01076)] 
  [[code](https://github.com/JudasDie/SOTS)]
  
- **GKB:** Zhiyu Zhu, Junhui Hou, Xianqiang Lyu.<br />
  "Leaning Graph-embedded Key-event Back-tracing for Object Tracking in Event Clouds." NeurIPS (2022).
  [[paper](https://nips.cc/Conferences/2022/Schedule?showEvent=54651)] 
  [[code](https://github.com/xxxx)]
  
- **TAP-Vid:** Carl Doersch, Ankush Gupta, Larisa Markeeva, Lucas Smaira, Yusuf Aytar, Andrew Zisserman, Yi Yang.<br />
  "TAP-Vid: A Benchmark for Tracking Any Point in a Video." NeurIPS (2022).
  [[paper](https://arxiv.org/abs/2211.03726)] 
  [[code](https://github.com/deepmind/tapnet)]

  
### ECCV 2022

- **OSTrack:** Botao Ye, Hong Chang, Bingpeng Ma, Shiguang Shan.<br />
  "Joint Feature Learning and Relation Modeling for Tracking: A One-Stream Framework." ECCV (2022).
  [[paper](https://arxiv.org/abs/2203.11991)] 
  [[code](https://github.com/botaoye/OSTrack)]
  
- **Unicorn:** Bin Yan, Yi Jiang, Peize Sun, Dong Wang, Zehuan Yuan, Ping Luo, Huchuan Lu.<br />
  "Unicorn: Towards Grand Unification of Object Tracking." ECCV (2022) Oral.
  [[paper](https://arxiv.org/abs/2207.07078)] 
  [[code](https://github.com/MasterBin-IIAU/Unicorn)]
  
- **SimTrack:** Boyu Chen, Peixia Li, Lei Bai, Lei Qiao, Qiuhong Shen, Bo Li, Weihao Gan, Wei Wu, Wanli Ouyang.<br />
  "Backbone is All Your Need: A Simplified Architecture for Visual Object Tracking." ECCV (2022).
  [[paper](https://arxiv.org/abs/2203.05328)] 
  [[code](https://github.com/LPXTT/SimTrack)]
  
- **CIA:** Zhixiong Pi, Weitao Wan, Chong Sun, Changxin Gao, Nong Sang, Chen Li.<br />
  "Hierarchical Feature Embedding for Visual Tracking." ECCV (2022).
  [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/4400_ECCV_2022_paper.php)] 
  [[code](https://github.com/zxgravity/CIA)]
  
- **RTS:** Matthieu Paul,Martin Danelljan,Christoph Mayer,Luc Van Gool.<br />
  "Robust Visual Tracking by Segmentation." ECCV (2022).
  [[paper](https://arxiv.org/abs/2203.11191)] 
  [[code](https://github.com/visionml/pytracking)]
  
- **AiATrack:** Shenyuan Gao, Chunluan Zhou, Chao Ma, Xinggang Wang, Junsong Yuan.<br />
  "AiATrack: Attention in Attention for Transformer Visual Tracking." ECCV (2022).
  [[paper](https://arxiv.org/abs/2207.09603)] 
  [[code](https://github.com/Little-Podi/AiATrack)]

- **SLTtrack:** Minji Kim, Seungkwan Lee, Jungseul Ok, Bohyung Han, Minsu Cho.<br />
  "Towards Sequence-Level Training for Visual Tracking." ECCV (2022).
  [[paper](https://arxiv.org/abs/2208.05810)] 
  [[code](https://github.com/byminji/SLTtrack)]
  
- **FEAR:** Vasyl Borsuk, Roman Vei, Orest Kupyn, Tetiana Martyniuk, Igor Krashenyi, Jiři Matas.<br />
  "FEAR: Fast, Efficient, Accurate and Robust Visual Tracker." ECCV (2022).
  [[paper](https://arxiv.org/pdf/2112.07957.pdf)] 
  [[code](https://xxxxxxx)]
  
- **PersonPath22:** Bing Shuai, Alessandro Bergamo, Uta Buechler, Andrew Berneshawi, Alyssa Boden, Joseph Tighe.<br />
  "Large Scale Real-World Multi-Person Tracking." ECCV (2022).
  [[paper](https://arxiv.org/abs/2211.02175)] 
  [[code](https://amazon-science.github.io/tracking-dataset/personpath22.html)]
  
- **STNet:** Le Hui, Lingpeng Wang, Linghua Tang, Kaihao Lan, Jin Xie, Jian Yang.<br />
  "3D Siamese Transformer Network for Single Object Tracking on Point Clouds." ECCV (2022).
  [[paper](https://arxiv.org/abs/2207.11995)] 
  [[code](https://github.com/fpthink/STNet)]
  
- **P3AFormer:** Zelin Zhao, Ze Wu, Yueqing Zhuang, Boxun Li, Jiaya Jia.<br />
  "Tracking Objects as Pixel-wise Distributions." ECCV (2022).
  [[paper](https://arxiv.org/abs/2207.05518)] 
  [[code](https://sjtuytc.github.io/zelin_pages/p3aformer.html)]
  
- **TETer:** Siyuan Li, Martin Danelljan, Henghui Ding, Thomas E. Huang, Fisher Yu.<br />
  "Tracking Every Thing in the Wild." ECCV (2022).
  [[paper](https://arxiv.org/abs/2207.12978)] 
  [[code](http://vis.xyz/pub/tet)]
  
- **ByteTrack:** Yifu Zhang, Peize Sun, Yi Jiang, Dongdong Yu, Zehuan Yuan, Ping Luo, Wenyu Liu, Xinggang Wang.<br />
  "ByteTrack: Multi-Object Tracking by Associating Every Detection Box." ECCV (2022).
  [[paper](https://arxiv.org/pdf/2110.06864v2.pdf)] 
  [[code](https://github.com/ifzhang/ByteTrack)]

- **MOTR:** Fangao Zeng, Bin Dong, Yuang Zhang, Tiancai Wang, Xiangyu Zhang, Yichen Wei.<br />
  "MOTR: End-to-End Multiple-Object Tracking with Transformer." ECCV (2022).
  [[paper](https://arxiv.org/abs/2105.03247)] 
  [[code](https://github.com/megvii-research/MOTR)]
  
- **MTracker:** Yifu Zhang, Chunyu Wang, Xinggang Wang, Wenjun Zeng, Wenyu Liu.<br />
  "Robust Multi-Object Tracking by Marginal Inference." ECCV (2022).
  [[paper](https://arxiv.org/abs/2208.03727)] 
  [[code](https://xxxxxxx)]
  

  
  
### CVPR 2022

- **MixFormer:** Yutao Cui, Jiang Cheng, Limin Wang, Gangshan Wu.<br />
  "MixFormer: End-to-End Tracking with Iterative Mixed Attention." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.11082)] 
  [[code](https://github.com/MCG-NJU/MixFormer)]
  
- **OWTB:** Yang Liu, Idil Esen Zulfikar, Jonathon Luiten, Achal Dave, Deva Ramanan, Bastian Leibe, Aljoša Ošep, Laura Leal-Taixé.<br />
  "Opening up Open-World Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2104.11221)] 
  [[code](https://openworldtracking.github.io/)]
  
- **UTT:** Fan Ma, Mike Zheng Shou, Linchao Zhu, Haoqi Fan, Yilei Xu, Yi Yang, Zhicheng Yan.<br />
  "Unified Transformer Tracker for Object Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.15175)] 
  [[code](https://github.com/Flowerfan/Trackron)]
  
- **CSWinTT:** Zikai Song, Junqing Yu, Yi-Ping Phoebe Chen, Wei Yang.<br />
  "Transformer Tracking with Cyclic Shifting Window Attention." CVPR (2022).
  [[paper](https://arxiv.org/abs/2205.03806)] 
  [[code](https://github.com/SkyeSong38/CSWinTT)]
  
- **ToMP:** Christoph Mayer, Martin Danelljan, Goutam Bhat, Matthieu Paul, Danda Pani Paudel, Fisher Yu, Luc Van Gool.<br />
  "Transforming Model Prediction for Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.11192)] 
  [[code](https://github.com/visionml/pytracking)]
  
- **TCTrack:** Ziang Cao, Ziyuan Huang, Liang Pan, Shiwei Zhang, Ziwei Liu, Changhong Fu.<br />
  "TCTrack: Temporal Contexts for Aerial Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.01885)] 
  [[code](https://github.com/vision4robotics/TCTrack)]
  
- **SBT:** Fei Xie, Chunyu Wang, Guangting Wang, Yue Cao, Wankou Yang, Wenjun Zeng.<br />
  "Correlation-Aware Deep Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.01666)] 
  [[code](https://github.com/phiphiphi31/SuperSBT)]
  
- **AdaRS:** Yihao Li, Jun Yu, Zhongpeng Cai, Yuwen Pan.<br />
  "Cross-Modal Target Retrieval for Tracking by Natural Language." CVPR (2022).
  [[paper](https://openaccess.thecvf.com/content/CVPR2022W/ODRUM/html/Li_Cross-Modal_Target_Retrieval_for_Tracking_by_Natural_Language_CVPRW_2022_paper.html)] 
  [[code](xxxx)]
  
- **STNet:** Jiqing Zhang, Bo Dong, Haiwei Zhang, Jianchuan Ding, Felix Heide, Baocai Yin, Xin Yang.<br />
  "Spiking Transformers for Event-based Single Object Tracking." CVPR (2022).
  [[paper](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Spiking_Transformers_for_Event-Based_Single_Object_Tracking_CVPR_2022_paper.html)] 
  [[code](https://github.com/Jee-King/CVPR2022_STNet)]
  
- **VTUAV:** Pengyu Zhang, Jie Zhao, Dong Wang, Huchuan Lu, Xiang Ruan.<br />
  "Visible-Thermal UAV Tracking: A Large-Scale Benchmark and New Baseline." CVPR (2022).
  [[paper](https://arxiv.org/abs/2204.04120)] 
  [[code](https://zhang-pengyu.github.io/DUT-VTUAV/)]
  
- **UAVMOT:** Shuai Liu, Xin Li, Huchuan Lu, You He.<br />
  "Multi-Object Tracking Meets Moving UAV." CVPR (2022).
  [[paper](https://arxiv.org/abs/xxxx.xxxx)] 
  [[code](https://github.com/LiuShuaiyr/UAVMOT)]
  
- **GTR:** Xingyi Zhou, Tianwei Yin, Vladlen Koltun, Phillip Krähenbühl.<br />
  "Global Tracking Transformers." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.13250)] 
  [[code](https://github.com/xingyizhou/GTR)]
  
- **GTELT:** Zikun Zhou, Jianqiu Chen, Wenjie Pei, Kaige Mao, Hongpeng Wang, Zhenyu He.<br />
  "Global Tracking via Ensemble of Local Trackers." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.16092)] 
  [[code](https://github.com/ZikunZhou/GTELT)]
  
- **RBO:** Feng Tang, Qiang Ling.<br />
  "Ranking-based Siamese Visual Tracking." CVPR (2022).
  [[paper](https://arxiv.org/pdf/2205.11761.pdf)] 
  [[code](https://github.com/sansanfree/RBO)]
  
- **ULAST:** Qiuhong Shen, Lei Qiao, Jinyang Guo, Peixia Li, Xin Li, Bo Li, Weitao Feng, Weihao Gan, Wei Wu, Wanli Ouyang.<br />
  "Unsupervised Learning of Accurate Siamese Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2204.01475)] 
  [[code](https://github.com/FlorinShum/ULAST)]
  
- **UDAT:** Junjie Ye, Changhong Fu, Guangze Zheng, Danda Pani Paudel, Guang Chen.<br />
  "Unsupervised Domain Adaptation for Nighttime Aerial Tracking." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.10541)] 
  [[code](https://github.com/vision4robotics/UDAT)]
  
- **M2Track:** Chaoda Zheng, Xu Yan, Haiming Zhang, Baoyuan Wang, Shenghui Cheng, Shuguang Cui, Zhen Li.<br />
  "Beyond 3D Siamese Tracking: A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds." CVPR (2022).
  [[paper](https://arxiv.org/abs/2203.01730)] 
  [[code](https://github.com/Ghostish/Open3DSOT)]
  

### IJCAI 2022

- **InBN:** Mingzhe Guo, Zhipeng Zhang, Heng Fan, Liping Jing, Yilin Lyu, Bing Li, Weiming Hu.<br />
  "Learning Target-aware Representation for Visual Tracking via Informative Interactions." IJCAI (2022).
  [[paper](https://arxiv.org/abs/2201.02526)] 
  [[code](https://xxxxxxx)]
  
- **SparseTT:** Zhihong Fu, Zehua Fu, Qingjie Liu, Zehua Fu, Yunhong Wang.<br />
  "SparseTT: Visual Tracking with Sparse Transformers." IJCAI (2022).
  [[paper](https://arxiv.org/abs/2205.03776)] 
  [[code](https://github.com/fzh0917/SparseTT)]
  
- **HybTransT:** Ilchae Jung, Minji Kim, Eunhyeok Park, Bohyung Han.<br />
  "Online Hybrid Lightweight Representations Learning: Its Application to Visual Tracking." IJCAI (2022).
  [[paper](https://arxiv.org/abs/2205.11179)] 
  [[code](https://github.com/fzh0917/SparseTT)]
  
  
### MICCAI 2022

- **TLT:** Wen Tang, Han Kang, Haoyue Zhang, Pengxin Yu, Corey W. Arnold, Rongguo Zhang.<br />
  "Transformer Lesion Tracker." MICCAI (2022).
  [[paper](https://arxiv.org/abs/2206.06252)] 
  [[code](https://github.com/TangWen920812/TLT)]
  
  
### ArXiv 2022
 
- **ProTrack:** Jinyu Yang, Zhe Li, Feng Zheng, Aleš Leonardis, Jingkuan Song.<br />
  "Prompting for Multi-Modal Tracking." ACM MM (2022).
  [[paper](https://arxiv.org/abs/2207.14571)] 
  [[code](https://)]
  
- **GATransT:** Libo Wang, Si Chen, Zhen Wang, Da-Han Wang, Shunzhi Zhu.<br />
  "Graph Attention Transformer Network for Robust Visual Tracking." ICONIP (2022).
  [[paper](https://link.springer.com/chapter/10.1007/978-981-99-1639-9_14)] 
  [[code]()]

- **SiamTDN:** Yanjie Liang, Penghui Zhao, Yifei Hao, Hanzi Wang.<br />
  "Siamese Template Diffusion Networks for Robust Visual Tracking." ICME (2022).
  [[paper](https://ieeexplore.ieee.org/document/9859929)] 
  [[code]()]
  
- **TAT:** Kaihao Lan, Haobo Jiang, Jin Xie.<br />
  "Temporal-aware Siamese Tracker: Integrate Temporal Context for 3D Object Tracking." ACCV (2022).
  [[paper](https://openaccess.thecvf.com/content/ACCV2022/html/Lan_Temporal-aware_Siamese_Tracker_Integrate_Temporal_Context_for_3D_Object_Tracking_ACCV_2022_paper.html)] 
  [[code](https://github.com/tqsdyy/TAT)]
  
 - **COESOT:** Chuanming Tang, Xiao Wang, Ju Huang, Bo Jiang, Lin Zhu, Jianlin Zhang, Yaowei Wang, Yonghong Tian.<br />
  "Revisiting Color-Event based Tracking: A Unified Network, Dataset, and Metric." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2211.11010)] 
  [[code](COESOT)]
  
- **WATB:** Fasheng Wang, Ping Cao, Fu Li, Xing Wang, Bing He, Fuming Sun.<br />
  "WATB: Wild Animal Tracking Benchmark." IJCV (2022).
  [[paper](https://link.springer.com/content/pdf/10.1007/s11263-022-01732-3.pdf?pdf=button)] 
  [[code](https://w-1995.github.io/)]
  
- **UAV2UAV:** Yong Wang, Zirong Huang, Robert Laganière, Huanlong Zhang, Lu Ding.<br />
  "A UAV to UAV tracking benchmark." KBS (2023).
  [[paper](https://www.sciencedirect.com/science/article/pii/S095070512201293X)] 
  [[code](https://github.com/hapless19/UAV2UAV-dataset)]
  
- **UOT100:** K. Panetta, L. Kezebou, V. Oludare, and S. S. Agaian.<br />
  "Comprehensive Underwater Object Tracking Benchmark Dataset and Underwater Image Enhancement With GAN." IEEE JOE (2022).
  [[paper](https://ieeexplore.ieee.org/document/9499961)] 
  [[code](https://www.kaggle.com/datasets/landrykezebou/uot100-underwater-object-tracking-dataset)]
  
- **NeighborTrack:** Yu-Hsi Chen, Chien-Yao Wang, Cheng-Yun Yang, Hung-Shuo Chang, Youn-Long Lin, Yung-Yu Chuang, Hong-Yuan Mark Liao.<br />
  "NeighborTrack: Improving Single Object Tracking by Bipartite Matching with Neighbor Tracklets." ArXiv (2022).
  [[paper](https://arxiv.org/pdf/2211.06663.pdf)] 
  [[code](https   )]
  
- **MTTSiam:** Ali Sekhavati, Won-Sook Lee.<br />
  "Multi-Template Temporal Siamese Network for Long-Term Object Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2211.13812)] 
  [[code](https://github.com/AliGreen0/MTTSiam)]
  
- **PruningInTracking:** Saksham Aggarwal, Taneesh Gupta, Pawan Kumar Sahu, Arnav Chavan, Rishabh Tiwari, Dilip K. Prasad, Deepak K. Gupta.<br />
  "On designing light-weight object trackers through network pruning: Use CNNs or transformers?." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2211.13769)] 
  [[code](https   )]
  
- **ProContEXT:** Jin-Peng Lan, Zhi-Qi Cheng, Jun-Yan He, Chenyang Li, Bin Luo, Xu Bao, Wangmeng Xiang, Yifeng Geng, Xuansong Xie.<br />
  "ProContEXT: Exploring Progressive Context Transformer for Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2210.15511)] 
  [[code](https://drive.google.com/drive/folders/18kHdBNEwvbk8S4-mwHaI-mw5w6cK-pyY?usp=sharing)]
  
- **TSFMO:** Zhewen Zhang, Fuliang Wu, Yuming Qiu, Jingdong Liang, Shuiwang Li.<br />
  "Tracking Small and Fast Moving Objects: A Benchmark." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2209.04284)] 
  [[code](https://github.com/CodeOfGithub/S-KeepTrack)]
  
- **SFTransT:** Chuanming Tang, Xiao Wang, Yuanchao Bai, Zhe Wu, Jianlin Zhang, Yongmei Huang.<br />
  "Learning Spatial-Frequency Transformer for Visual Object Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2208.08829)] 
  [[code](https://github.com/Tchuanm/SFTransT.git)]
  
- **DMTracker:** Shang Gao, Jinyu Yang, Zhe Li, Feng Zheng, Aleš Leonardis, Jingkuan Song.<br />
  "Learning Dual-Fused Modality-Aware Representations for RGBD Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2211.03055)] 
  [[code](https://github.com/ShangGaoG/DMTracker)]
  
- **AVisT:** Mubashir Noman, Wafa Al Ghallabi, Daniya Najiha, Christoph Mayer, Akshay Dudhane, Martin Danelljan, Hisham Cholakkal, Salman Khan, Luc Van Gool, Fahad Shahbaz Khan.<br />
  "AVisT: A Benchmark for Visual Object Tracking in Adverse Visibility." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2208.06888)] 
  [[code](https://github.com/visionml/pytracking)]

- **RGBDReview:** Jinyu Yang, Zhe Li, Song Yan, Feng Zheng, Aleš Leonardis, Joni-Kristian Kämäräinen, Ling Shao.<br />
  "RGBD Object Tracking: An In-depth Review." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2203.14134)] 
  [[code](https://github.com/memoryunreal/RGBD-tracking-review)]
  
- **TOT/MKDNet:** Yabin Zhu, Chenglong Li, Yao Liu, Xiao Wang, Jin Tang, Bin Luo, Zhixiang Huang.<br />
  "Tiny Object Tracking: A Large-scale Dataset and A Baseline." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2202.05659)] 
  [[code](https://github.com/mmic-lcl/Datasets-and-benchmark-code)]
  
- **WebUAV-3M:** Chunhui Zhang, Guanjie Huang, Li Liu, Shan Huang, Yinan Yang, Yuxuan Zhang, Xiang Wan, Shiming Ge.<br />
  "WebUAV-3M: A Benchmark Unveiling the Power of Million-Scale Deep UAV Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2201.07425)] 
  [[code](https://github.com/983632847/WebUAV-3M)]
  
- **SiamTracking4UAV:** Changhong Fu, Kunhan Lu, Guangze Zheng, Junjie Ye, Ziang Cao, Bowen Li.<br />
  "Siamese Object Tracking for Unmanned Aerial Vehicle: A Review and Comprehensive Analysis." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2205.04281)] 
  [[code](https://github.com/vision4robotics/SiameseTracking4UAV)]
  
- **SOTSurvey:** Zahra Soleimanitaleb, Mohammad Ali Keyvanrad.<br />
  "Single Object Tracking: A Survey of Methods, Datasets, and Evaluation Metrics." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2201.13066)] 
  
- **SOTRearch:** Ruize Han, Wei Feng, Qing Guo, Qinghua Hu.<br />
  "Single Object Tracking Research: A Survey." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2204.11410)] 
  
- **VOTSurvey:** Fei Chen, Xiaodong Wang, Yunxiang Zhao, Shaohe Lv, Xin Niu.<br />
  "Visual object tracking: A survey." CVIU (2022).
  [[paper](https://www.sciencedirect.com/science/article/pii/S1077314222001011?dgcid=author)] 
    
- **HCAT:** Xin Chen, Dong Wang, Dongdong Li, Huchuan Lu.<br />
  "Efficient Visual Tracking via Hierarchical Cross-Attention Transformer." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2203.13537)] 
  [[code](https://github.com/chenxin-dlut/HCAT)]
  
- **TransT-M:** Xin Chen, Bin Yan, Jiawen Zhu, Dong Wang, Huchuan Lu.<br />
  "High-Performance Transformer Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2203.13533)] 
  [[code](https://github.com/chenxin-dlut/TransT-M)]
  
- **RGBDT:** Jinyu Yang, Zhe Li, Song Yan, Feng Zheng, Aleš Leonardis, Joni-Kristian Kämäräinen, Ling Shao.<br />
  "RGBD Object Tracking: An In-depth Review." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2203.14134)] 
  [[code](https://github.com/memoryunreal/RGBD-tracking-review)]
  
- **DST:** Yao Sui, Guanghui Wang, Li Zhang.<br />
  "In Defense of Subspace Tracker: Orthogonal Embedding for Visual Tracking." ArXiv (2022).
  [[paper](https://arxiv.org/abs/2204.07927)] 
  [[code](https://xxxxxxx)]
  
- **DUT-Anti-UAV:** Jie Zhao, Jingshu Zhang, Dongdong Li, Dong Wang.<br />
  "Vision-based Anti-UAV Detection and Tracking." TITS (2022).
  [[paper](https://arxiv.org/abs/2205.10851)] 
  [[code](https://github.com/wangdongdut/DUT-Anti-UAV)]
  
- **CoCoLoT:** Matteo Dunnhofer, Christian Micheloni.<br />
  "CoCoLoT: Combining Complementary Trackers in Long-Term Visual Tracking." ICPR (2022).
  [[paper](https://arxiv.org/abs/2205.04261)] 
  [[code](https://xxxxxxx)]
  
- **EUSA:** Siao Liu, Zhaoyu Chen, Wei Li, Jiwei Zhu, Jiafeng Wang, Wenqiang Zhang, Zhongxue Gan.<br />
  "Efficient universal shuffle attack for visual object tracking." ICASSP (2022).
  [[paper](https://arxiv.org/abs/2203.06898)] 
  [[code](https://xxxxxxx)]
  
- **ITB:** Xin Li, Qiao Liu, Wenjie Pei, Qiuhong Shen, Yaowei Wang, Huchuan Lu, Ming-Hsuan Yang.<br />
  "An Informative Tracking Benchmark." ArXiv (2021).
  [[paper](https://arxiv.org/abs/2112.06467)] 
  [[code](https://github.com/XinLi-zn/Informative-tracking-benchmark)]
  
- **VisEvent:** Xiao Wang, Jianing Li, Lin Zhu, Zhipeng Zhang, Zhe Chen, Xin Li, Yaowei Wang, Yonghong Tian, Feng Wu.<br />
  "VisEvent: Reliable Object Tracking via Collaboration of Frame and Event Flows." ArXiv (2021).
  [[paper](https://arxiv.org/abs/2108.05015)] 
  [[code](https://sites.google.com/view/viseventtrack/)]
  
- **TrTr:** Moju Zhao, Kei Okada, Masayuki Inaba.<br />
  "TrTr: Visual Tracking with Transformer." ArXiv (2021).
  [[paper](https://arxiv.org/pdf/2105.03817.pdf)] 
  [[code](https://github.com/tongtybj/TrTr)]

- **TS-RCN:** Ning Zhang, Jingen Liu, Ke Wang, Dan Zeng, Tao Mei.<br />
  "Robust Visual Object Tracking with Two-Stream Residual Convolutional Networks." ArXiv (2020).
  [[paper](https://arxiv.org/pdf/2005.06536.pdf)] 
  [[code](https://github.com/xxxxx/xxxx)]
  
- **FCOT:** Yutao Cui, Cheng Jiang, Limin Wang, Gangshan Wu.<br />
  "Fully Convolutional Online Tracking." ArXiv (2020).
  [[paper](https://arxiv.org/abs/2004.07109)] 
  [[code](https://github.com/MCG-NJU/FCOT)]
  
  
### AAAI 2022

- **HDN:** Xinrui Zhan, Yueran Liu, jianke Zhu, Yang Li.<br />
  "Homography Decomposition Networks for Planar Object Tracking." AAAI (2022).
  [[paper](https://arxiv.org/pdf/2112.07909.pdf)] 
  [[code](https://github.com/zhanxinrui/HDN)]

- **MArMOT:** Chenglong Li, Tianhao Zhu, Lei Liu, Xiaonan Si, Zilin Fan, Sulan Zhai.<br />
  "Cross-Modal Object Tracking: Modality-Aware Representations and a Unified Benchmark." AAAI (2022).
  [[paper](https://arxiv.org/abs/2111.04264)] 
  [[code](https://github.com/xxxxx/MArMOT)]

- **APFNet:** Yun Xiao, Mengmeng Yang, Chenglong Li, Lei Liu, Jin Tang.<br />
  "Attribute-based Progressive Fusion Network for RGBT Tracking." AAAI (2022).
  [[paper](https://github.com/yangmengmeng1997/APFNet/tree/main/Paper)] 
  [[code](https://github.com/yangmengmeng1997/APFNet)]

- **TAV:** Tahar Allouche, Jerome Lang, Florian Yger.<br />
  "Truth-Tracking via Approval Voting: Size Matters." AAAI (2022).
  [[paper](https://arxiv.org/abs/2112.04387)] 
  [[code](https://github.com/zhanxinrui/HDN)]
  
  
### ICLR 2022

- **FSBA:** Yiming Li, Haoxiang Zhong, Xingjun Ma, Yong Jiang, Shu-Tao Xia.<br />
  "Few-Shot Backdoor Attacks on Visual Object Tracking." ICLR (2022).
  [[paper](https://openreview.net/pdf?id=qSV5CuSaK_a)] 
  [[code](https://www.dropbox.com/s/nfg7en8azc1cvz3/codes_FSBA_ICLR22.zip?dl=0)]
  
  
### ICRA 2022

- **Ad2Attack:** Changhong Fu, Sihang Li, Xinnan Yuan, Junjie Ye, Ziang Cao, Fangqiang Ding.<br />
  "Ad2Attack: Adaptive Adversarial Attack on Real-Time UAV Tracking." ICRA (2022).
  [[paper](https://arxiv.org/abs/2203.01516)] 
  [[code](https://github.com/vision4robotics/Ad2Attack)]
 
- **SCT:** Junjie Ye, Changhong Fu, Ziang Cao, Shan An, Guangze Zheng, Bowen Li.<br />
  "Tracker Meets Night: A Transformer Enhancer for UAV Tracking." ICRA/RAL (2022).
  [[paper](https://ieeexplore.ieee.org/document/9696362)] 
  [[code](https://github.com/vision4robotics/SCT)]

- **SiamX:** Huajian Huang, Sai-Kit Yeung.<br />
  "SiamX: An Efficient Long-term Tracker Using Cross-level Feature Correlation and Adaptive Tracking Scheme." ICRA (2022).
  [[paper](https://huajianup.github.io/research/SiamX/SiamX_ICRA2022_final.pdf)] 
  [[code](https://huajianup.github.io/research/SiamX/)]
 
 
### WACV 2022

- **SiamTPN:** Daitao Xing, Nikolaos Evangeliou, Athanasios Tsoukalas, Anthony Tzes.<br />
  "Siamese Transformer Pyramid Networks for Real-Time UAV Tracking." WACV (2022).
  [[paper](https://arxiv.org/pdf/2110.08822.pdf)] 
  [[code](https://github.com/RISC-NYUAD/SiamTPNTracker)]
  
### ICCV 2021

- **STARK:** Bin Yan, Houwen Peng, Jianlong Fu, Dong Wang, Huchuan Lu.<br />
  "Learning Spatio-Temporal Transformer for Visual Tracking." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2103.17154.pdf)] 
  [[code](https://github.com/researchmm/Stark)]
  
- **AutoMatch:**  Zhang Zhipeng, Liu Yihao, Wang Xiao, Li Bing, Hu Weiming. <br />
  "Learn to Match: Automatic Matching Network Design for Visual Tracking." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2108.00803.pdf)]
  [[code](https://github.com/JudasDie/SOTS)]
  
- **DDT:** Bin Yu, Ming Tang, Linyu Zheng, Guibo Zhu, Jinqiao Wang.<br />
  "High-Performance Discriminative Tracking with Transformers." ICCV (2021).
  [[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Yu_High-Performance_Discriminative_Tracking_With_Transformers_ICCV_2021_paper.pdf)] 
  [[code](https://github.com/xxxx/xxxx)]
  
- **HiFT:**  Ziang Cao, Changhong Fu, Junjie Ye, Bowen Li, Yiming Li. <br />
  "HiFT: Hierarchical Feature Transformer for Aerial Tracking." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2108.00202.pdf)]
  [[code](https://github.com/vision4robotics/HiFT)]
  
- **DualTFR:**  Fei Xie, Chunyu Wang, Guangting Wang, Wankou Yang, Wenjun Zeng. <br />
  "Learning Tracking Representations via Dual-Branch Fully Transformer Networks." ICCVW (2021).
  [[paper](https://arxiv.org/abs/2112.02571)]
  [[code](https://github.com/phiphiphi31/DualTFR)]
  
- **DMB:**  Fei Xie, Wankou Yang, Kaihua Zhang, Bo Liu, Wanli Xue, Wangmeng Zuo. <br /> 
  "Learning Spatio-Appearance Memory Network for High-Performance Visual Tracking." ICCVW (2021).
  [[paper](https://arxiv.org/pdf/2009.09669.pdf)]
  [[code](https://github.com/phiphiphi31/DMB)]

- **KeepTrack:** Christoph Mayer, Martin Danelljan, Danda Pani Paudel, Luc Van Gool.<br />
  "Learning Target Candidate Association to Keep Track of What Not to Track." ICCV (2021).
  [[paper](https://arxiv.org/abs/2103.16556)] 
  [[code](https://github.com/visionml/pytracking)]

- **SAOT:** Zikun Zhou, Wenjie Pei, Xin Li, Hongpeng Wang, Feng Zheng, Zhenyu He. <br />
  "Saliency-Associated Object Tracking." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2108.03637.pdf)]
  [[code](https://github.com/ZikunZhou/SAOT)]
 
- **MLVSNet:** Zhoutao Wang, Qian Xie, Yu-Kun Lai, Jing Wu, Kun Long , Jun Wang. <br />
  "MLVSNet: Multi-level Voting Siamese Network for 3D Visual Tracking." ICCV (2021).
  [[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_MLVSNet_Multi-Level_Voting_Siamese_Network_for_3D_Visual_Tracking_ICCV_2021_paper.pdf)]
  [[code](https://github.com/CodeWZT/MLVSNet)]
  
 - **EFTrack:** Jiqing Zhang, Xin Yang, Yingkai Fu, Xiaopeng Wei, Baocai Yin, Bo Dong. <br />
  "Object Tracking by Jointly Exploiting Frame and Event Domain." ICCV (2021).
  [[paper](https://arxiv.org/abs/2109.09052)]
  [[code](https://github.com/Jee-King/ICCV2021_Event_Frame_Tracking)]
  
 - **Box2Mask:** Bin Zhao, Goutam Bhat, Martin Danelljan, Luc Van Gool, Radu Timofte. <br />
  "Generating Masks from Boxes by Mining Spatio-Temporal Consistencies in Videos." ICCV (2021).
  [[paper](https://arxiv.org/abs/2101.02196)]
  [[code](https://github.com/visionml/pytracking)]
  
- **DepthTrack:** Song Yan, Jinyu Yang, Jani Käpylä, Feng Zheng, Aleš Leonardis, Joni-Kristian Kämäräinen. <br />
  "DepthTrack : Unveiling the Power of RGBD Tracking." ICCV (2021).
  [[paper](https://arxiv.org/abs/2108.13962)]
  [[code](https://github.com/xiaozai/DeT)]
  
- **USOT:** Jilai Zheng, Chao Ma, Houwen Peng, Xiaokang Yang. <br />
  "Learning to Track Objects from Unlabeled Videos." ICCV (2021).
  [[paper](https://arxiv.org/abs/2108.12711)]
  [[code](https://github.com/VISION-SJTU/USOT)]
  
- **TOTB:** Heng Fan, Halady Akhilesha Miththanthaya, Harshit, Siranjiv Ramana Rajan, Xiaoqiong Liu, Zhilin Zou, Yuewei Lin, Haibin Ling. <br />
  "Transparent Object Tracking Benchmark." ICCV (2021).
  [[paper](https://arxiv.org/abs/2011.10875)]
  [[code](https://hengfan2010.github.io/projects/TOTB/)]
  
- **TREK-150:** Matteo Dunnhofer, Antonino Furnari, Giovanni Maria Farinella, Christian Micheloni. <br />
  "Is First Person Vision Challenging for Object Tracking?." ICCVW (2021).
  [[paper](https://arxiv.org/abs/2108.13665)]
  [[code](https://machinelearning.uniud.it/datasets/trek150/)]
  [[toolkit](https://github.com/matteo-dunnhofer/TREK-150-toolkit)]
  
- **VASR:** Kenan Dai, Jie Zhao, Lijun Wang, Dong Wang, Jianhua Li, Huchuan Lu, Xuesheng Qian, Xiaoyun Yang. <br />
  "Video Annotation for Visual Tracking via Selection and Refinement." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2108.03821.pdf)]
  [[code](https://github.com/Daikenan/VASR)]
  
- **BAT:** Chaoda Zheng, Xu Yan, Jiantao Gao, Weibing Zhao, Wei Zhang, Zhen Li, Shuguang Cui. <br />
  "Box-Aware Feature Enhancement for Single Object Tracking on Point Clouds." ICCV (2021).
  [[paper](https://arxiv.org/pdf/2108.04728.pdf)]
  [[code](https://github.com/Ghostish/BAT)]
  
- **ABA:** Qing Guo, Ziyi Cheng, Felix Juefei-Xu, Lei Ma, Xiaofei Xie, Yang Liu, Jianjun Zhao. <br />
  "Learning to Adversarially Blur Visual Object Tracking." ICCV (2021).
  [[paper](https://arxiv.org/abs/2107.12085)]
  [[code](https://github.com/tsingqguo/ABA)]
  
  
### CVPR 2021

- **TransT:** Xin Chen, Bin Yan, Jiawen Zhu, Dong Wang, Xiaoyun yang, Huchuan Lu. <br />
  "Transformer Tracking." CVPR (2021).
  [[paper](https://arxiv.org/abs/2103.15436)]
  [[code](https://github.com/chenxin-dlut/TransT)]
  
- **Alpha-Refine:** Bin Yan, Xinyu Zhang, Dong Wang, Huchuan Lu, Xiaoyun Yang. <br />
  "Alpha-Refine: Boosting Tracking Performance by Precise Bounding Box Estimation." CVPR (2021).
  [[paper](https://arxiv.org/pdf/1911.12836.pdf)]
  [[code](https://github.com/MasterBin-IIAU/AlphaRefine)]
  
- **LightTrack:** Bin Yan, Houwen Peng, Kan Wu, Dong Wang, Jianlong Fu, Huchuan Lu. <br />
  "LightTrack: Finding Lightweight Neural Networks for Object Tracking via One-Shot Architecture Search." CVPR (2021).
  [[paper](https://arxiv.org/abs/2104.14545)]
  [[code](https://github.com/cvpr-2021/lighttrack)]
  
- **TrTrack:** Ning Wang, Wengang Zhou, Jie Wang, Houqiang Li. <br />
  "Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2103.11681.pdf)]
  [[code](https://github.com/594422814/TransformerTrack)]
  
- **STMTrack:** Zhihong Fu, Qingjie Liu, Zehua Fu, Yunhong Wang. <br />
  "STMTrack: Template-free Visual Tracking with Space-time Memory Networks." CVPR (2021).
  [[paper](https://arxiv.org/abs/2104.00324)]
  [[code](https://github.com/fzh0917/STMTrack)]
  
- **SiamGAT:** Dongyan Guo, Yanyan Shao, Ying Cui, Zhenhua Wang, Liyan Zhang, Chunhua Shen.<br />
  "Graph Attention Tracking." CVPR (2021).
  [[paper](https://arxiv.org/abs/2011.11204)] 
  [[code](https://github.com/ohhhyeahhh/SiamGAT)]
  
- **SiamACM:** Wencheng Han, Xingping Dong, Fahad Shahbaz Khan, Ling Shao, Jianbing Shen.<br />
  "Learning to Fuse Asymmetric Feature Maps in Siamese Trackers." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2012.02776.pdf)] 
  [[code](https://github.com/wencheng256/SiamBAN-ACM)]
  
- **PST:** Gunhee Nam, Miran Heo, Seoung Wug Oh, Joon-Young Lee, Seon Joo Kim.<br />
  "Polygonal Point Set Tracking." CVPR (2021).
  [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Nam_Polygonal_Point_Set_Tracking_CVPR_2021_paper.pdf)] 
  [[code](https://github.com/PST)]
  
- **PUL:** Qiangqiang Wu, Jia Wan, Antoni B. Chan. <br />
  "Progressive Unsupervised Learning for Visual Object Tracking." CVPR (2021).
  [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Progressive_Unsupervised_Learning_for_Visual_Object_Tracking_CVPR_2021_paper.pdf)]
  [[code](https://github.com/PUL)]
  
- **CapsuleRRT:** Ding Ma, Xiangqian Wu. <br />
  "CapsuleRRT: Relationships-Aware Regression Tracking via Capsules." CVPR (2021).
  [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Ma_CapsuleRRT_Relationships-Aware_Regression_Tracking_via_Capsules_CVPR_2021_paper.pdf)]
  [[code](https://github.com/CapsuleRRT)]
  
- **Semi-Track:** Yang Fu, Sifei Liu, Umar Iqbal, Shalini De Mello, Humphrey Shi, Jan Kautz.<br />
  "Learning to Track Instances without Video Annotations." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2104.00287.pdf)] 
  [[code](https://oasisyang.github.io/projects/semi-track/index.html)]

- **RE-Siam:** Deepak K. Gupta, Devanshu Arya, Efstratios Gavves. <br />
  "Rotation Equivariant Siamese Networks for Tracking." CVPR (2021).
  [[paper](https://arxiv.org/abs/2012.13078)]
  [[code](https://github.com/dkgupta90/re-siamnet)]
  
- **SiamNLP:** Qi Feng, Vitaly Ablavsky, Qinxun Bai, Stan Sclaroff. <br />
  "Siamese Natural Language Tracker: Tracking by Natural Language Descriptions with Siamese Trackers." CVPR (2021).
  [[paper](https://arxiv.org/abs/1912.02048v2)]
  [[code](https://github.com/fredfung007/snlt)]
  
- **LangTrackBenchmark:** Xiao Wang, Xiujun Shu, Zhipeng Zhang, Bo Jiang, Yaowei Wang, Yonghong Tian, Feng Wu. <br />
  "Towards More Flexible and Accurate Object Tracking with Natural Language: Algorithms and Benchmark." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2103.16746.pdf)]
  [[code](https://sites.google.com/view/langtrackbenchmark/)]
  
- **DroneCrowd:** Longyin Wen, Dawei Du, Pengfei Zhu, Qinghua Hu, Qilong Wang, Liefeng Bo, Siwei Lyu. <br />
  "Detection, Tracking, and Counting Meets Drones in Crowds: A Benchmark." CVPR (2021).
  [[paper](https://arxiv.org/pdf/2105.02440.pdf)]
  [[code](https://github.com/VisDrone/DroneCrowd)]
  
- **DMTrack:** Zikai Zhang, Bineng Zhong, Shengping Zhang, Zhenjun Tang, Xin Liu, Zhaoxiang Zhang. <br />
  "Distractor-Aware Fast Tracking via Dynamic Convolutions and MOT Philosophy." CVPR (2021).
  [[paper](https://arxiv.org/abs/2104.12041)]
  [[code](https://github.com/hqucv/dmtrack)]
  
- **LF-Siam:** Siyuan Cheng, Bineng Zhong, Guorong Li, Xin Liu, Zhenjun Tang, Xianxian Li, Jing Wang. <br />
  "Learning to Filter: Siamese Relation Network for Robust Tracking." CVPR (2021).
  [[paper](https://arxiv.org/abs/2104.00829)]
  [[code](https://github.com/hqucv/siamrn)]
  
- **IoU Attack:** Shuai Jia, Yibing Song, Chao Ma, Xiaokang Yang. <br />
  "IoU Attack: Towards Temporally Coherent Black-Box Adversarial Attack for Visual Object Tracking." CVPR (2021).
  [[paper](https://arxiv.org/abs/2103.14938)]
  [[code](https://github.com/VISION-SJTU/IoUattack)]
  
- **MeanShift++:** Jennifer Jang, Heinrich Jiang. <br />
  "MeanShift++: Extremely Fast Mode-Seeking With Applications to Segmentation and Object Tracking." CVPR (2021).
  [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Jang_MeanShift_Extremely_Fast_Mode-Seeking_With_Applications_to_Segmentation_and_Object_CVPR_2021_paper.pdf)]
  [[code](https://github.com/MeanShift++)]
  
  
### IROS 2021

- **CRACT:** Heng Fan, Haibin Ling.<br />
  "CRACT: Cascaded Regression-Align-Classification for Robust Visual Tracking." IROS (2020).
  [[paper](https://arxiv.org/abs/2011.12483)] 

- **SiamAPN++:** Ziang Cao, Changhong Fu, Junjie Ye, Bowen Li, Yiming Li.<br />
  "SiamAPN++: Siamese Attentional Aggregation Network for Real-Time UAV Tracking." IROS (2021).
  [[paper](https://arxiv.org/pdf/2106.08816.pdf)] 
  [[code](https://github.com/vision4robotics/SiamAPN)]

- **DarkLighter:** Junjie Ye, Changhong Fu, Guangze Zheng, Ziang Cao, Bowen Li.<br />
  "DarkLighter: Light Up the Darkness for UAV Tracking." IROS (2021).
  [[paper](https://arxiv.org/pdf/2107.14389.pdf)] 
  [[code](https://github.com/vision4robotics/DarkLighter)]
  
- **PTT:** Jiayao Shan, Sifan Zhou, Zheng Fang, Yubo Cui.<br />
  "PTT: Point-Track-Transformer Module for 3D Single Object Tracking in Point Clouds." IROS (2021).
  [[paper](https://arxiv.org/abs/2108.06455)] 
  [[code](https://github.com/shanjiayao/PTT)]
  
  
### NeurIPS 2021

- **PathTrack:** Drew Linsley, Girik Malik, Junkyung Kim, Lakshmi Narasimhan Govindarajan, Ennio Mingolla, Thomas Serre.<br />
  "Tracking Without Re-recognition in Humans and Machines." NeurIPS (2021).
  [[paper](https://proceedings.neurips.cc/paper/2021/hash/a2557a7b2e94197ff767970b67041697-Abstract.html)] 
  [[code](http://bit.ly/InTcircuit)]
  
- **UniTrack:** Zhongdao Wang, Hengshuang Zhao, Ya-Li Li, Shengjin Wang, Philip Torr, Luca Bertinetto.<br />
  "Do Different Tracking Tasks Require Different Appearance Models?." NeurIPS (2021).
  [[paper](https://proceedings.neurips.cc/paper/2021/hash/06997f04a7db92466a2baa6ebc8b872d-Abstract.html)] 
  [[code](https://zhongdao.github.io/UniTrack/)]

  
### WACV 2021

- **MART:** Heng Fan, Haibin Ling.<br />
  "MART: Motion-Aware Recurrent Neural Network for Robust Visual Tracking." WACV (2021).
  [[paper](https://openaccess.thecvf.com/content/WACV2021/papers/Fan_MART_Motion-Aware_Recurrent_Neural_Network_for_Robust_Visual_Tracking_WACV_2021_paper.pdf)] 
  [[code](https://hengfan2010.github.io/projects/MART/MART.htm)]
  
- **SiamSE:** Ivan Sosnovik, Artem Moskalev, Arnold Smeulders.<br />
  "Scale Equivariance Improves Siamese Tracking." WACV (2021).
  [[paper](https://arxiv.org/pdf/2007.09115.pdf)] 
  [[code](https://github.com/ISosnovik/SiamSE)]
  
- **TracKlinic:** Heng Fan, Fan Yang, Peng Chu, Yuewei Lin, Lin Yuan, Haibin Ling. <br />
  "TracKlinic: Diagnosis of Challenge Factors in Visual Tracking." WACV (2021).
  [[paper](https://arxiv.org/abs/1911.07959)]
  [[code](https://hengfan2010.github.io/projects/TracKlinic/TracKlinic.htm.)]
  
  
### AAAI 2021

- **MUG:** Lijun Zhou, Antoine Ledent, Qintao Hu, Ting Liu, Jianlin Zhang, Marius Kloft.<br />
  "Model Uncertainty Guides Visual Object Tracking." AAAI (2021).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16473)] 
  
- **UPA:** Li Ding, Yongwei Wang, Kaiwen Yuan, Minyang Jiang, Ping Wang, Hua Huang, Z. Jane Wang. <br />
  "Towards Universal Physical Attacks on Single Object Tracking." AAAI (2021).
  [[paper](https://www.aaai.org/AAAI21Papers/AAAI-2606.DingL.pdf)]

- **PACNet:** Dawei Zhang, Zhonglong Zheng, Riheng Jia, Minglu Li.<br />
  "Visual Tracking via Hierarchical Deep Reinforcement Learning." AAAI (2021).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16443)] 
  
- **MSANet:** Xuesong Chen, Canmiao Fu, Feng Zheng, Yong Zhao, Hongsheng Li, Ping Luo, Guo-Jun Qi. <br />
  "A Unified Multi-Scenario Attacking Network for Visual Object Tracking." AAAI (2021).
  [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/16195)]
  

### Others 2021

- **SiamAPN:** Changhong Fu, Ziang Cao, Yiming Li, Junjie Ye, Chen Feng.<br />
  "Onboard Real-Time Aerial Tracking with Efficient Siamese Anchor Proposal Network." IEEE TGRS (2021).
  [[paper](https://ieeexplore.ieee.org/document/9477413)] 
  [[code](https://github.com/vision4robotics/SiamAPN)]
  
- **CCR:** Shiming Ge, Chunhui Zhang, Shikun Li, Dan Zeng, Dacheng Tao.<br />
  "Cascaded Correlation Refinement for Robust Deep Tracking." IEEE TNNLS (2021).
  [[paper](https://ieeexplore.ieee.org/document/9069312)] 
  [[code](https://github.com/983632847/CCR)]
  
- **CHASE:** Seyed Mojtaba Marvasti-Zadeh, Javad Khaghani, Li Cheng, Hossein Ghanei-Yakhdan, Shohreh Kasaei.<br />
  "CHASE: Robust Visual Tracking via Cell-Level Differentiable Neural Architecture Search." BMVC (2021).
  [[paper](https://arxiv.org/abs/2107.03463)] 
  
### ECCV 2020

- **Ocean:** Zhipeng Zhang, Houwen Peng, Jianlong Fu, Bing Li, Weiming Hu. <br />
  "Ocean: Object-aware Anchor-free Tracking." ECCV (2020).
  [[paper](https://arxiv.org/pdf/2006.10721.pdf)]
  [[code](https://github.com/researchmm/TracKit)]
  
- **KYS:** Goutam Bhat, Martin Danelljan, Luc Van Gool, Radu Timofte. <br />
  "Know Your Surroundings: Exploiting Scene Information for Object Tracking." ECCV (2020).
  [[paper](https://arxiv.org/pdf/2003.11014v1.pdf)]
  [[code](https://github.com/visionml/pytracking)]
  
- **PGNet:** Bingyan Liao, Chenye Wang, Yayun Wang, Yaonong Wang, Jun Yin. <br />
  "PG-Net: Pixel to Global Matching Network for Visual Tracking." ECCV (2020).
  [[paper](https://arxiv.org/abs/2003.11014)]
  
- **STN:** Yuan Liu, Ruoteng Li, Yu Cheng, Robby T.Tan, Xiubao Sui. <br />
  "Object Tracking using Spatio-Temporal Networks for Future Prediction Location." ECCV (2020).
  [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123670001.pdf)]
  
- **RPT:** Ziang Ma, Linyuan Wang, Haitao Zhang, Wei Lu, Jun Yin. <br />
  "RPT: Learning Point Set Representation for Siamese Visual Tracking." ECCVW (2020).
  [[paper](https://arxiv.org/abs/2008.03467)]
  [[code](https://github.com/zhanght021/RPT)]
  
- **CenterTrack:** Xingyi Zhou, Vladlen Koltun, and Philipp Krahenbuhl. <br />
  "Tracking objects as points." ECCV (2020).
  [[paper](https://arxiv.org/abs/2004.01177)]
  [[code](https://github.com/xingyizhou/CenterTrack)]
  
- **PointTracker:** Zhenbo Xu, Wei Zhang, Xiao Tan, Wei Yang, Huan Huang, Shilei Wen, Errui Ding, Liusheng Huang. <br />
  "Segment as Points for Efficient Online Multi-Object Tracking and Segmentation." ECCV (2020).
  [[paper](https://arxiv.org/abs/2007.01550)]
  [[code](https://github.com/detectRecog/PointTrack)]
  
- **DCFST:** Linyu Zheng, Ming Tang, Yingying Chen, Jinqiao Wang, Hanqing Lu. <br />
  "Learning Feature Embeddings for Discriminant Model based Tracking." ECCV (2020).
  [[paper](https://arxiv.org/abs/1906.10414)]
  [[code](https://github.com/noneUmbrella/DCFST)]
  
- **CLNet:** Xingping Dong, Jianbing Shen, Ling Shao, Fatih Porikli. <br />
  "CLNet: A Compact Latent Network for Fast Adjusting Siamese Tracker." ECCV (2020).
  [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123650375.pdf)]
  [[code](https://github.com/xingpingdong/CLNet-tracking)]
  
- **RTAA:** Shuai Jia, Chao Ma, Yibing Song, Xiaokang Yang. <br />
  "Robust Tracking against Adversarial Attacks." ECCV (2020).
  [[paper](https://arxiv.org/abs/2007.09919)]
  [[code](https://github.com/joshuajss/RTAA)]
  
- **EAA:** Siyuan Liang, Xingxing Wei, Siyuan Yao, Xiaochun Cao. <br />
  "Efficient Adversarial Attacks for Visual Object Tracking." ECCV (2020).
  [[paper](https://arxiv.org/abs/2008.00217)]

- **SPARK:** Qing Guo, Xiaofei Xie, Felix Juefei-Xu, Lei Ma, Zhongguo Li, Wanli Xue, Wei Feng, Yang Liu. <br />
  "SPARK: Spatial-aware Online Incremental Attack Against Visual Tracking." ECCV (2020).
  [[paper](https://arxiv.org/pdf/1910.08681.pdf)]
  
- **CAT:** Chenglong Li, Lei Liu, Andong Lu, Qing Ji, Jin Tang. <br />
  "Challenge-Aware RGBT Tracking." ECCV (2020).
  [[paper](https://arxiv.org/abs/2007.13143)]

- **JDE:** Zhongdao Wang, Liang Zheng, Yixuan Liu, Shengjin Wang. <br />
  "Towards Real-Time Multi-Object Tracking." ECCV (2020).
  [[paper](https://arxiv.org/pdf/1909.12605v1.pdf)]
  [[code](https://gitee.com/mat026/Towards-Realtime-MOT)]
  
- **Chained-Tracker:** Jinlong Peng, Changan Wang, Fangbin Wan, Yang Wu, Yabiao Wang, Ying Tai, Chengjie Wang, Jilin Li, Feiyue Huang, Yanwei Fu. <br />
  "Chained-Tracker: Chaining Paired Attentive Regression Results for End-to-End Joint Multiple-Object Detection and Tracking." ECCV (2020).
  [[paper](https://arxiv.org/pdf/2007.14557.pdf)]
  [[code](https://github.com/pjl1995/CTracker)]
  
- **TAO:** Achal Dave, Tarasha Khurana, Pavel Tokmakov, Cordelia Schmid, Deva Ramanan. <br />
  "TAO: A Large-scale Benchmark for Tracking Any Object." ECCV (2020).
  [[paper](https://arxiv.org/abs/2005.10356)]
  [[code](http://taodataset.org/)]

### CVPR2020

* **MAML:** Guangting Wang, Chong Luo, Xiaoyan Sun, Zhiwei Xiong, Wenjun Zeng.<br />
  "Tracking by Instance Detection: A Meta-Learning Approach." CVPR (2020 **Oral**).
  [[paper](https://arxiv.org/pdf/2004.00830v1.pdf)]

* **Siam R-CNN:** Paul Voigtlaender, Jonathon Luiten, Philip H.S. Torr, Bastian Leibe.<br />
  "Siam R-CNN: Visual Tracking by Re-Detection." CVPR (2020).
  [[BoLTVOS](https://arxiv.org/pdf/1904.04552.pdf)] 
  [[paper](https://arxiv.org/pdf/1911.12836.pdf)] 
  [[code](https://www.vision.rwth-aachen.de/page/siamrcnn)]

* **D3S:** Alan Lukežič, Jiří Matas, Matej Kristan.<br />
  "D3S – A Discriminative Single Shot Segmentation Tracker." CVPR (2020).
  [[paper](http://arxiv.org/pdf/1911.08862v2.pdf)]
  [[code](https://github.com/alanlukezic/d3s)]

* **PrDiMP:** Martin Danelljan, Luc Van Gool, Radu Timofte.<br />
  "Probabilistic Regression for Visual Tracking." CVPR (2020).
  [[paper](https://arxiv.org/pdf/2003.12565v1.pdf)]
  [[code](https://github.com/visionml/pytracking)]

* **ROAM:** Tianyu Yang, Pengfei Xu, Runbo Hu, Hua Chai, Antoni B. Chan.<br />
  "ROAM: Recurrently Optimizing Tracking Model." CVPR (2020).
  [[paper](https://arxiv.org/pdf/1907.12006v3.pdf)]
  [[code](https://github.com/skyoung/ROAM)]

* **AutoTrack:** Yiming Li, Changhong Fu, Fangqiang Ding, Ziyuan Huang, Geng Lu.<br />
  "AutoTrack: Towards High-Performance Visual Tracking for UAV with Automatic Spatio-Temporal Regularization." CVPR (2020).
  [[paper](https://arxiv.org/pdf/2003.12949.pdf)]
  [[code](https://github.com/vision4robotics/AutoTrack)]

* **SiamBAN:** Zedu Chen, Bineng Zhong, Guorong Li, Shengping Zhang, Rongrong Ji.<br />
  "Siamese Box Adaptive Network for Visual Tracking." CVPR (2020).
  [[paper](http://arxiv.org/pdf/1911.08862v2.pdf)]
  [[code](https://github.com/hqucv/siamban)]

* **SiamCAR:** Dongyan Guo, Jun Wang, Ying Cui, Zhenhua Wang, Shengyong Chen.<br />
  "SiamCAR: Siamese Fully Convolutional Classification and Regression for Visual Tracking." CVPR (2020).
  [[paper](https://arxiv.org/abs/1911.07241)]
  [[code](https://github.com/ohhhyeahhh/SiamCAR)]

* **SiamAttn:** Yuechen Yu, Yilei Xiong, Weilin Huang, Matthew R. Scott. <br />
  "Deformable Siamese Attention Networks for Visual Object Tracking." CVPR (2020).
  [[paper](https://arxiv.org/pdf/2004.06711v1.pdf)]
  
* **CSA:** Bin Yan, Dong Wang, Huchuan Lu, Xiaoyun Yang.<br />
  "Cooling-Shrinking Attack: Blinding the Tracker with Imperceptible Noises." CVPR (2020).
  [[paper](https://arxiv.org/abs/2003.09595)]
  [[code](https://github.com/MasterBin-IIAU/CSA)]

* **LTMU:** Kenan Dai, Yunhua Zhang, Dong Wang, Jianhua Li, Huchuan Lu, Xiaoyun Yang.<br />
  "High-Performance Long-Term Tracking with Meta-Updater." CVPR (2020).
  [[paper](https://arxiv.org/abs/2004.00305)]
  [[code](https://github.com/Daikenan/LTMU)]
  
* **MAST:** Zihang Lai, Erika Lu, Weidi Xie.<br />
  "MAST: A Memory-Augmented Self-supervised Tracker." CVPR (2020).
  [[paper](https://arxiv.org/abs/2002.07793)]
  [[code](https://github.com/zlai0/MAST)]
  
* **CGACD:** Fei Du, Peng Liu, Wei Zhao, Xianglong Tang.<br />
  "Correlation-Guided Attention for Corner Detection Based Visual Tracking." CVPR (2020).
  [[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Du_Correlation-Guided_Attention_for_Corner_Detection_Based_Visual_Tracking_CVPR_2020_paper.pdf)]
  [[code](https://github.com/feiaxyt/CGACD)]

### IJCAI 2020

- **TLPG-Tracker:** Siyuan Li, Zhi Zhang, Ziyu Liu, Anna Wang, Linglong Qiu, Feng Du. <br />
  "TLPG-Tracker: Joint Learning of Target Localization and Proposal Generation for Visual Tracking." IJCAI (2020).
  [[paper](https://www.ijcai.org/Proceedings/2020/99)]
  
- **E3SN:** Meng Lan, Yipeng Zhang, Qinning Xu, Lefei Zhang. <br />
  "E3SN: Efficient End-to-End Siamese Network for Video Object Segmentation." IJCAI (2020).
  [[paper](https://www.ijcai.org/Proceedings/2020/98)]
  
### AAAI 2020

- **SiamFC++:** Yinda Xu, Zeyu Wang, Zuoxin Li, Ye Yuan, Gang Yu. <br />
  "SiamFC++: Towards Robust and Accurate Visual Tracking with Target Estimation Guidelines." AAAI (2020).
  [[paper](https://arxiv.org/pdf/1911.06188v4.pdf)]
  [[code](https://github.com/MegviiDetection/video_analyst)]
  
- **DROL:** Jinghao Zhou, Peng Wang, Haoyang Sun. <br />
  "Discriminative and Robust Online Learning for Siamese Visual Tracking." AAAI (2020).
  [[paper](https://arxiv.org/abs/1909.02959)]
  [[code](https://github.com/shallowtoil/DROL)]
  
- **POST:** Ning Wang, Wengang Zhou, Guojun Qi, Houqiang Li. <br />
  "POST: POlicy-Based Switch Tracking." AAAI (2020).
  [[paper](https://ojs.aaai.org//index.php/AAAI/article/view/6899)]
  
- **SPS:** Qintao Hu, Lijun Zhou, Xiaoxiao Wang, Yao Mao, Jianlin Zhang, Qixiang Ye. <br />
  "SPSTracker: Sub-Peak Suppression of Response Map for Robust Object Tracking." AAAI (2020).
  [[paper](https://arxiv.org/pdf/1912.00597.pdf)]
  [[code](https://www.ctolib.com/https://github.com/TrackerLB/SPSTracker)]
  
- **RPOT:** Yifan Yang, Guorong Li, Yuankai Qi, Qingming Huang. <br />
  "Release the Power of Online-Training for Robust Visual Tracking." AAAI (2020).
  [[paper](https://ojs.aaai.org//index.php/AAAI/article/view/6956)]
  
- **MetaRTT:** Ilchae Jung, Kihyun You, Hyeonwoo Noh, Minsu Cho, Bohyung Han. <br />
  "Real-Time Object Tracking via Meta-Learning: Efficient Model Adaptation and One-Shot Channel Pruning." AAAI (2020).
  [[paper](https://ojs.aaai.org//index.php/AAAI/article/view/6779)]
  
- **GlobalTrack:** Lianghua Huang, Xin Zhao, Kaiqi Huang. <br />
  "GlobalTrack: A Simple and Strong Baseline for Long-term Tracking." AAAI (2020).
  [[paper](https://arxiv.org/abs/1912.08531)]
  [[code](https://github.com/huanglianghua/GlobalTrack)]

### Others 2020

* **VTT:** Tianling Bian, Yang Hua, Tao Song, Zhengui Xue, Ruhui Ma, Neil Robertson, Haibing Guan.<br />
  "VTT: Long-term Visual Tracking with Transformers." ICPR 2020. 
  [[paper](https://pure.qub.ac.uk/en/publications/vtt-long-term-visual-tracking-with-transformers)]
  [[code](https://github.com/VisualTrackingVLL)]
  
* **COMET:** Seyed Mojtaba Marvasti-Zadeh, Javad Khaghani, Hossein Ghanei-Yakhdan, Shohreh Kasaei, and Li Cheng.<br />
  "COMET: Context-aware iOu-guided network for sMall objEct Tracking." ACCV 2020. 
  [[paper](https://arxiv.org/pdf/2006.02597.pdf)]
  [[code](https://github.com/VisualTrackingVLL)]
  
* **SiamKPN:** Qiang Li, Zekui Qin, Wenbo Zhang, Wen Zheng.<br />
  "Siamese Keypoint Prediction Network for Visual Object Tracking." ArXiv 2020. 
  [[paper](https://arxiv.org/abs/2006.04078)]
  [[code](https://github.com/ZekuiQin/SiamKPN)]

* **SiamCAN:** Wenzhang Zhou, Longyin Wen, Libo Zhang, Dawei Du, Tiejian Luo, Yanjun Wu. <br />
  "SiamMan: Siamese Motion-aware Network for Visual Tracking." TIP 2020. 
  [[paper](https://arxiv.org/abs/1912.05515v2)]
  [[paper_new](https://arxiv.org/abs/1912.05515v2)]
  [[code](https://isrc.iscas.ac.cn/gitlab/research/siamcan)]
  
### ICCV 2019

* **DiMP:** Goutam Bhat, Martin Danelljan, Luc Van Gool, Radu Timofte.<br />
  "Learning Discriminative Model Prediction for Tracking." ICCV (2019 **oral**). 
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Bhat_Learning_Discriminative_Model_Prediction_for_Tracking_ICCV_2019_paper.pdf)]
  [[code](https://github.com/visionml/pytracking)]

* **GradNet:** Peixia Li, Boyu Chen, Wanli Ouyang, Dong Wang, Xiaoyun Yang, Huchuan Lu. <br />
  "GradNet: Gradient-Guided Network for Visual Object Tracking." ICCV (2019 **oral**).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Li_GradNet_Gradient-Guided_Network_for_Visual_Object_Tracking_ICCV_2019_paper.pdf)]
  [[code](https://github.com/LPXTT/GradNet-Tensorflow)]

* **MLT:** Janghoon Choi, Junseok Kwon, Kyoung Mu Lee. <br />
  "Deep Meta Learning for Real-Time Target-Aware Visual Tracking." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Choi_Deep_Meta_Learning_for_Real-Time_Target-Aware_Visual_Tracking_ICCV_2019_paper.pdf)]

* **SPLT:** Bin Yan, Haojie Zhao, Dong Wang, Huchuan Lu, Xiaoyun Yang <br />
  "'Skimming-Perusal' Tracking: A Framework for Real-Time and Robust Long-Term Tracking." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Yan_Skimming-Perusal_Tracking_A_Framework_for_Real-Time_and_Robust_Long-Term_Tracking_ICCV_2019_paper.pdf)]
  [[code](https://github.com/iiau-tracker/SPLT)]

* **ARCF:** Ziyuan Huang, Changhong Fu, Yiming Li, Fuling Lin, Peng Lu. <br />
  "Learning Aberrance Repressed Correlation Filters for Real-Time UAV Tracking." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_Learning_Aberrance_Repressed_Correlation_Filters_for_Real-Time_UAV_Tracking_ICCV_2019_paper.pdf)]
  [[code](https://github.com/vision4robotics/ARCF-tracker)]

* **BGDT:** Lianghua Huang, Xin Zhao, Kaiqi Huang. <br />
  "Bridging the Gap Between Detection and Tracking: A Unified Approach." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_Bridging_the_Gap_Between_Detection_and_Tracking_A_Unified_Approach_ICCV_2019_paper.pdf)]

* **PAT:** Rey Reza Wiyatno, Anqi Xu. <br />
  "Physical Adversarial Textures That Fool Visual Object Tracking." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Wiyatno_Physical_Adversarial_Textures_That_Fool_Visual_Object_Tracking_ICCV_2019_paper.pdf)]

* **GFS-DCF:** Tianyang Xu, Zhen-Hua Feng, Xiao-Jun Wu, Josef Kittler. <br />
  "Joint Group Feature Selection and Discriminative Filter Learning for Robust Visual Object Tracking." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Xu_Joint_Group_Feature_Selection_and_Discriminative_Filter_Learning_for_Robust_ICCV_2019_paper.pdf)]
  [[code](https://github.com/XU-TIANYANG/GFS-DCF)]

* **CDTB:** Alan Lukežič, Ugur Kart, Jani Käpylä, Ahmed Durmush, Joni-Kristian Kämäräinen, Jiří Matas, Matej Kristan. <br />
  "CDTB: A Color and Depth Visual Object Tracking Dataset and Benchmark." ICCV (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2019/papers/Lukezic_CDTB_A_Color_and_Depth_Visual_Object_Tracking_Dataset_and_ICCV_2019_paper.pdf)]
  
* **fdKCF:** Linyu Zheng, Ming Tang, Yingying Chen, Jinqiao Wang, Hanqing Lu. <br />
  "Fast-deepKCF Without Boundary Effect." ICCV (2019).
  [[paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Zheng_Fast-deepKCF_Without_Boundary_Effect_ICCV_2019_paper.pdf)]

* **VOT2019:** Kristan, Matej, et al.<br />
  "The Seventh Visual Object Tracking VOT2019 Challenge Results." ICCV workshops (2019).
  [[paper](http://openaccess.thecvf.com/content_ICCVW_2019/papers/VOT/Kristan_The_Seventh_Visual_Object_Tracking_VOT2019_Challenge_Results_ICCVW_2019_paper.pdf)]

### CVPR2019

* **SiamMask:** Qiang Wang, Li Zhang, Luca Bertinetto, Weiming Hu, Philip H.S. Torr.<br />
  "Fast Online Object Tracking and Segmentation: A Unifying Approach." CVPR (2019). 
  [[paper](https://arxiv.org/pdf/1812.05050.pdf)]
  [[project](http://www.robots.ox.ac.uk/~qwang/SiamMask/)]
  [[code](https://github.com/foolwood/SiamMask)]

* **SiamRPN++:** Bo Li, Wei Wu, Qiang Wang, Fangyi Zhang, Junliang Xing, Junjie Yan.<br />
  "SiamRPN++: Evolution of Siamese Visual Tracking with Very Deep Networks." CVPR (2019 **oral**). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_SiamRPN_Evolution_of_Siamese_Visual_Tracking_With_Very_Deep_Networks_CVPR_2019_paper.pdf)]
  [[project](http://bo-li.info/SiamRPN++/)]

* **ATOM:** Martin Danelljan, Goutam Bhat, Fahad Shahbaz Khan, Michael Felsberg. <br />
  "ATOM: Accurate Tracking by Overlap Maximization." CVPR (2019 **oral**). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Danelljan_ATOM_Accurate_Tracking_by_Overlap_Maximization_CVPR_2019_paper.pdf)]
  [[code](https://github.com/visionml/pytracking)]

* **SiamDW:** Zhipeng Zhang, Houwen Peng.<br />
  "Deeper and Wider Siamese Networks for Real-Time Visual Tracking." CVPR (2019 **oral**). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Deeper_and_Wider_Siamese_Networks_for_Real-Time_Visual_Tracking_CVPR_2019_paper.pdf)]
  [[code](https://github.com/researchmm/SiamDW)]

* **GCT:** Junyu Gao, Tianzhu Zhang, Changsheng Xu.<br />
  "Graph Convolutional Tracking." CVPR (2019 **oral**).
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Gao_Graph_Convolutional_Tracking_CVPR_2019_paper.pdf)]
  [[code](https://github.com/researchmm/SiamDW)]

* **ASRCF:** Kenan Dai, Dong Wang, Huchuan Lu, Chong Sun, Jianhua Li. <br />
  "Visual Tracking via Adaptive Spatially-Regularized Correlation Filters." CVPR (2019 **oral**).
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Dai_Visual_Tracking_via_Adaptive_Spatially-Regularized_Correlation_Filters_CVPR_2019_paper.pdf)]
  [[code](https://github.com/Daikenan/ASRCF)]

* **UDT:** Ning Wang, Yibing Song, Chao Ma, Wengang Zhou, Wei Liu, Houqiang Li.<br />
  "Unsupervised Deep Tracking." CVPR (2019). 
  [[paper](https://arxiv.org/pdf/1904.01828.pdf)]
  [[code](https://github.com/594422814/UDT)]

* **TADT:** Xin Li, Chao Ma, Baoyuan Wu, Zhenyu He, Ming-Hsuan Yang.<br />
  "Target-Aware Deep Tracking." CVPR (2019). 
  [[paper](https://arxiv.org/pdf/1904.01772.pdf)]
  [[project](https://xinli-zn.github.io/TADT-project-page/)]
  [[code](https://github.com/XinLi-zn/TADT)]

* **C-RPN:** Heng Fan, Haibin Ling.<br />
  "Siamese Cascaded Region Proposal Networks for Real-Time Visual Tracking." CVPR (2019). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Fan_Siamese_Cascaded_Region_Proposal_Networks_for_Real-Time_Visual_Tracking_CVPR_2019_paper.pdf)]

* **SPM:** Guangting Wang, Chong Luo, Zhiwei Xiong, Wenjun Zeng.<br />
  "SPM-Tracker: Series-Parallel Matching for Real-Time Visual Object Tracking." CVPR (2019). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_SPM-Tracker_Series-Parallel_Matching_for_Real-Time_Visual_Object_Tracking_CVPR_2019_paper.pdf)]

* **OTR:** Ugur Kart, Alan Lukezic, Matej Kristan, Joni-Kristian Kamarainen, Jiri Matas. <br />
  "Object Tracking by Reconstruction with View-Specific Discriminative Correlation Filters." CVPR (2019). 
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Kart_Object_Tracking_by_Reconstruction_With_View-Specific_Discriminative_Correlation_Filters_CVPR_2019_paper.pdf)]
  [[code](https://github.com/ugurkart/OTR)]

* **RPCF:** Yuxuan Sun, Chong Sun, Dong Wang, Huchuan Lu, You He. <br />
  "ROI Pooled Correlation Filters for Visual Tracking." CVPR (2019).
  [[paper](http://openaccess.thecvf.com/content_CVPR_2019/papers/Sun_ROI_Pooled_Correlation_Filters_for_Visual_Tracking_CVPR_2019_paper.pdf)]

* **LaSOT:** Heng Fan, Liting Lin, Fan Yang, Peng Chu, Ge Deng, Sijia Yu, Hexin Bai, Yong Xu, Chunyuan Liao, Haibin Ling.<br />
  "LaSOT: A High-quality Benchmark for Large-scale Single Object Tracking." CVPR (2019). 
  [[paper](https://arxiv.org/pdf/1809.07845.pdf)]
  [[project](https://cis.temple.edu/lasot/)]

### AAAI2019

* **LDES:** Yang Li, Jianke Zhu, Steven C.H. Hoi, Wenjie Song, Zhefeng Wang, Hantang Liu.<br />
  "Robust Estimation of Similarity Transformation for Visual Object Tracking." AAAI (2019). 
  [[paper](https://arxiv.org/pdf/1712.05231.pdf)]
  [[code](https://github.com/ihpdep/LDES)] 
  
* **ANT:** Yuankai Qi, Shengping Zhang, Weigang Zhang, Li Su, Qingming Huang, Ming-Hsuan Yang.<br />
  "Learning Attribute-Specific Representations for Visual Tracking." AAAI (2019). 
  [[paper](https://faculty.ucmerced.edu/mhyang/papers/aaai2019_tracking.pdf)]
  
* **Re2EMA:** Jianglei Huang, Wengang Zhou.<br />
  "Re2EMA: Regularized and Reinitialized Exponential Moving Average for Target Model Update in Object Tracking." AAAI (2019). 
  [[paper](https://ojs.aaai.org//index.php/AAAI/article/view/4862)]

### NIPS2018

* **DAT:** Shi Pu, Yibing Song, Chao Ma, Honggang Zhang, Ming-Hsuan Yang.<br />
  "Deep Attentive Tracking via Reciprocative Learning." NIPS (2018). 
  [[paper](https://arxiv.org/pdf/1810.03851.pdf)] 
  [[project](https://ybsong00.github.io/nips18_tracking/index)] 
  [[code](https://github.com/shipubupt/NIPS2018)] 

### ECCV2018

* **UPDT:** Goutam Bhat, Joakim Johnander, Martin Danelljan, Fahad Shahbaz Khan, Michael Felsberg.<br />
  "Unveiling the Power of Deep Tracking." ECCV (2018). 
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Goutam_Bhat_Unveiling_the_Power_ECCV_2018_paper.pdf)]  

* **DaSiamRPN:** Zheng Zhu, Qiang Wang, Bo Li, Wu Wei, Junjie Yan, Weiming Hu.<br />
  "Distractor-aware Siamese Networks for Visual Object Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Zheng_Zhu_Distractor-aware_Siamese_Networks_ECCV_2018_paper.pdf)]
  [[github](https://github.com/foolwood/DaSiamRPN)]
  
* **SiamMCF:** Henrique Morimitsu.<br />
  "Multiple Context Features in Siamese Networks for Visual Object Tracking." ECCV (2018).
  [[paper](https://link.springer.com/content/pdf/10.1007%2F978-3-030-11009-3_6.pdf)]
  [[github](https://github.com/hmorimitsu/siam-mcf)]

* **SACF:** Mengdan Zhang, Qiang Wang, Junliang Xing, Jin Gao, Peixi Peng, Weiming Hu, Steve Maybank.<br />
  "Visual Tracking via Spatially Aligned Correlation Filters Network." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/mengdan_zhang_Visual_Tracking_via_ECCV_2018_paper.pdf)]

* **RTINet:** Yingjie Yao, Xiaohe Wu, Lei Zhang, Shiguang Shan, Wangmeng Zuo.<br />
  "Joint Representation and Truncated Inference Learning for Correlation Filter based Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Yingjie_Yao_Joint_Representation_and_ECCV_2018_paper.pdf)]

* **Meta-Tracker:** Eunbyung Park, Alexander C. Berg.<br />
  "Meta-Tracker: Fast and Robust Online Adaptation for Visual Object Trackers."
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Eunbyung_Park_Meta-Tracker_Fast_and_ECCV_2018_paper.pdf)]
  [[github](https://github.com/silverbottlep/meta_trackers)]

* **DSLT:** Xiankai Lu, Chao Ma*, Bingbing Ni, Xiaokang Yang, Ian Reid, Ming-Hsuan Yang.<br />
  "Deep Regression Tracking with Shrinkage Loss." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Xiankai_Lu_Deep_Regression_Tracking_ECCV_2018_paper.pdf)]
  [[github](https://github.com/chaoma99/DSLT)]

* **DRL-IS:** Liangliang Ren, Xin Yuan, Jiwen Lu, Ming Yang, Jie Zhou.<br />
  "Deep Reinforcement Learning with Iterative Shift for Visual Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Liangliang_Ren_Deep_Reinforcement_Learning_ECCV_2018_paper.pdf)]

* **RT-MDNet:** Ilchae Jung, Jeany Son, Mooyeol Baek, Bohyung Han.<br />
  "Real-Time MDNet." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Ilchae_Jung_Real-Time_MDNet_ECCV_2018_paper.pdf)]

* **ACT:** Boyu Chen, Dong Wang, Peixia Li, Huchuan Lu.<br />
  "Real-time 'Actor-Critic' Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Boyu_Chen_Real-time_Actor-Critic_Tracking_ECCV_2018_paper.pdf)]
  [[github](https://github.com/bychen515/ACT)]

* **StructSiam:** Yunhua Zhang, Lijun Wang, Dong Wang, Mengyang Feng, Huchuan Lu, Jinqing Qi.<br />
  "Structured Siamese Network for Real-Time Visual Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Yunhua_Zhang_Structured_Siamese_Network_ECCV_2018_paper.pdf)]

* **MemTrack:** Tianyu Yang, Antoni B. Chan.<br />
  "Learning Dynamic Memory Networks for Object Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Tianyu_Yang_Learning_Dynamic_Memory_ECCV_2018_paper.pdf)]

* **SiamFC-tri:** Xingping Dong, Jianbing Shen.<br />
  "Triplet Loss in Siamese Network for Object Tracking." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Xingping_Dong_Triplet_Loss_with_ECCV_2018_paper.pdf)]
  [[github](https://github.com/shenjianbing/TripletTracking)]

* **OxUvA long-term dataset+benchmark:** Jack Valmadre, Luca Bertinetto, João F. Henriques, Ran Tao, Andrea Vedaldi, Arnold Smeulders, Philip Torr, Efstratios Gavves.<br />
  "Long-term Tracking in the Wild: a Benchmark." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Efstratios_Gavves_Long-term_Tracking_in_ECCV_2018_paper.pdf)]
  [[project](https://oxuva.github.io/long-term-tracking-benchmark/)]

* **TrackingNet:** Matthias Müller, Adel Bibi, Silvio Giancola, Salman Al-Subaihi, Bernard Ghanem.<br />
  "TrackingNet: A Large-Scale Dataset and Benchmark for Object Tracking in the Wild." ECCV (2018).
  [[paper](http://openaccess.thecvf.com/content_ECCV_2018/papers/Matthias_Muller_TrackingNet_A_Large-Scale_ECCV_2018_paper.pdf)] 
  [[project](http://tracking-net.org/)]


### CVPR2018

* **VITAL:** Yibing Song, Chao Ma, Xiaohe Wu, Lijun Gong, Linchao Bao, Wangmeng Zuo, Chunhua Shen, Rynson Lau, and Ming-Hsuan Yang.
  "VITAL: VIsual Tracking via Adversarial Learning." CVPR (2018 **Spotlight**). 
  [[project](https://ybsong00.github.io/cvpr18_tracking/index)]
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Song_VITAL_VIsual_Tracking_CVPR_2018_paper.pdf)]
  [[github](https://github.com/ybsong00/Vital_release)]

* **LSART:** Chong Sun, Dong Wang, Huchuan Lu, Ming-Hsuan Yang.
  "Learning Spatial-Aware Regressions for Visual Tracking." CVPR (2018 **Spotlight**). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Sun_Learning_Spatial-Aware_Regressions_CVPR_2018_paper.pdf)]

* **SiamRPN:** Bo Li, Wei Wu, Zheng Zhu, Junjie Yan.
  "High Performance Visual Tracking with Siamese Region Proposal Network." CVPR (2018 **Spotlight**). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Li_High_Performance_Visual_CVPR_2018_paper.pdf)]

* **TRACA:** Jongwon Choi, Hyung Jin Chang, Tobias Fischer, Sangdoo Yun, Kyuewang Lee, Jiyeoup Jeong, Yiannis Demiris, Jin Young Choi.
  "Context-aware Deep Feature Compression for High-speed Visual Tracking." CVPR (2018). 
  [[project](https://sites.google.com/site/jwchoivision/)]
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Choi_Context-Aware_Deep_Feature_CVPR_2018_paper.pdf)]

* **RASNet:** Qiang Wang, Zhu Teng, Junliang Xing, Jin Gao, Weiming Hu, Stephen Maybank.
  "Learning Attentions: Residual Attentional Siamese Network for High Performance Online Visual Tracking." CVPR 2018. 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Learning_Attentions_Residual_CVPR_2018_paper.pdf)]

* **SA-Siam:** Anfeng He, Chong Luo, Xinmei Tian, Wenjun Zeng.
  "A Twofold Siamese Network for Real-Time Object Tracking." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/He_A_Twofold_Siamese_CVPR_2018_paper.pdf)]

* **STRCF:** Feng Li, Cheng Tian, Wangmeng Zuo, Lei Zhang, Ming-Hsuan Yang.
  "Learning Spatial-Temporal Regularized Correlation Filters for Visual Tracking." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Li_Learning_Spatial-Temporal_Regularized_CVPR_2018_paper.pdf)]
  [[github](https://github.com/lifeng9472/STRCF)]

* **FlowTrack:** Zheng Zhu, Wei Wu, Wei Zou, Junjie Yan.
  "End-to-end Flow Correlation Tracking with Spatial-temporal Attention." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhu_End-to-End_Flow_Correlation_CVPR_2018_paper.pdf)]

* **DEDT:** Kourosh Meshgi, Shigeyuki Oba, Shin Ishii.
  "Efficient Diverse Ensemble for Discriminative Co-Tracking." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Meshgi_Efficient_Diverse_Ensemble_CVPR_2018_paper.pdf)]

* **SINT++:** Xiao Wang, Chenglong Li, Bin Luo, Jin Tang.
  "SINT++: Robust Visual Tracking via Adversarial Positive Instance Generation." CVPR (2018).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_SINT_Robust_Visual_CVPR_2018_paper.pdf)]

* **DRT:** Chong Sun, Dong Wang, Huchuan Lu, Ming-Hsuan Yang.
  "Correlation Tracking via Joint Discrimination and Reliability Learning." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Sun_Correlation_Tracking_via_CVPR_2018_paper.pdf)]

* **MCCT:** Ning Wang, Wengang Zhou, Qi Tian, Richang Hong, Meng Wang, Houqiang Li.
  "Multi-Cue Correlation Filters for Robust Visual Tracking." CVPR (2018). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Multi-Cue_Correlation_Filters_CVPR_2018_paper.pdf)]
  [[github](https://github.com/594422814/MCCT)]

* **MKCF:** Ming Tang, Bin Yu, Fan Zhang, Jinqiao Wang.
  "High-speed Tracking with Multi-kernel Correlation Filters." CVPR (2018).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Tang_High-Speed_Tracking_With_CVPR_2018_paper.pdf)]

* **HP:** Xingping Dong, Jianbing Shen, Wenguan Wang, Yu, Liu, Ling Shao, and Fatih Porikli.
  "Hyperparameter Optimization for Tracking with Continuous Deep Q-Learning." CVPR (2018).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Dong_Hyperparameter_Optimization_for_CVPR_2018_paper.pdf)]

### NIPS2017

* **HART:** Adam R. Kosiorek, Alex Bewley, Ingmar Posner. 
  "Hierarchical Attentive Recurrent Tracking." NIPS (2017). 
  [[paper](https://papers.nips.cc/paper/6898-hierarchical-attentive-recurrent-tracking.pdf)]
  [[github](https://github.com/akosiorek/hart)]


### ICCV2017

* **CREST:** Yibing Song, Chao Ma, Lijun Gong, Jiawei Zhang, Rynson Lau, Ming-Hsuan Yang. 
  "CREST: Convolutional Residual Learning for Visual Tracking." ICCV (2017 **Spotlight**). 
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Song_CREST_Convolutional_Residual_ICCV_2017_paper.pdf)]
  [[project](http://www.cs.cityu.edu.hk/~yibisong/iccv17/index.html)]
  [[github](https://github.com/ybsong00/CREST-Release)]

* **EAST:** Chen Huang, Simon Lucey, Deva Ramanan.
  "Learning Policies for Adaptive Tracking with Deep Feature Cascades." ICCV (2017 **Spotlight**). 
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Huang_Learning_Policies_for_ICCV_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Huang_Learning_Policies_for_ICCV_2017_supplemental.zip)]

* **PTAV:** Heng Fan and Haibin Ling. 
  "Parallel Tracking and Verifying: A Framework for Real-Time and High Accuracy Visual Tracking." ICCV (2017). 
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Fan_Parallel_Tracking_and_ICCV_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Fan_Parallel_Tracking_and_ICCV_2017_supplemental.pdf)]
  [[project](http://www.dabi.temple.edu/~hbling/code/PTAV/ptav.htm)]
  [[code](http://www.dabi.temple.edu/~hbling/code/PTAV/serial_ptav_v1.zip)]

* **BACF:** Hamed Kiani Galoogahi, Ashton Fagg, Simon Lucey. 
  "Learning Background-Aware Correlation Filters for Visual Tracking." ICCV (2017). 
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Galoogahi_Learning_Background-Aware_Correlation_ICCV_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Galoogahi_Learning_Background-Aware_Correlation_ICCV_2017_supplemental.pdf)]
  [[code](http://www.hamedkiani.com/uploads/5/1/8/8/51882963/bacf_toupload.zip)]
  [[project](http://www.hamedkiani.com/bacf.html)]

* **TSN:** Zhu Teng, Junliang Xing, Qiang Wang, Congyan Lang, Songhe Feng and Yi Jin.
  "Robust Object Tracking based on Temporal and Spatial Deep Networks." ICCV (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Teng_Robust_Object_Tracking_ICCV_2017_paper.pdf)]

* **p-tracker:** James Supančič, III; Deva Ramanan.
  "Tracking as Online Decision-Making: Learning a Policy From Streaming Videos With Reinforcement Learning." ICCV (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Supancic_Tracking_as_Online_ICCV_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Supancic_Tracking_as_Online_ICCV_2017_supplemental.pdf)]

* **DSiam:** Qing Guo; Wei Feng; Ce Zhou; Rui Huang; Liang Wan; Song Wang.
  "Learning Dynamic Siamese Network for Visual Object Tracking." ICCV (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Guo_Learning_Dynamic_Siamese_ICCV_2017_paper.pdf)]
  [[github](https://github.com/tsingqguo/DSiam)]

* **SP-KCF:** Xin Sun; Ngai-Man Cheung; Hongxun Yao; Yiluan Guo.
  "Non-Rigid Object Tracking via Deformable Patches Using Shape-Preserved KCF and Level Sets." ICCV (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Sun_Non-Rigid_Object_Tracking_ICCV_2017_paper.pdf)]

* **UCT:** Zheng Zhu, Guan Huang, Wei Zou, Dalong Du, Chang Huang.
  "UCT: Learning Unified Convolutional Networks for Real-Time Visual Tracking." ICCV workshop (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/Zhu_UCT_Learning_Unified_ICCV_2017_paper.pdf)]

* Tobias Bottger, Patrick Follmann.
  "The Benefits of Evaluating Tracker Performance Using Pixel-Wise Segmentations." ICCV workshop (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/Bottger_The_Benefits_of_ICCV_2017_paper.pdf)]

* **CFWCR:** Zhiqun He, Yingruo Fan, Junfei Zhuang, Yuan Dong, HongLiang Bai.
  "Correlation Filters With Weighted Convolution Responses." ICCV workshop (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/He_Correlation_Filters_With_ICCV_2017_paper.pdf)]
  [[github](https://github.com/he010103/CFWCR)]

* **IBCCF:** Feng Li, Yingjie Yao, Peihua Li, David Zhang, Wangmeng Zuo, Ming-Hsuan Yang.
  "Integrating Boundary and Center Correlation Filters for Visual Tracking With Aspect Ratio Variation." ICCV workshop (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/Li_Integrating_Boundary_and_ICCV_2017_paper.pdf)]
  [[github](https://github.com/lifeng9472/IBCCF)]

* **RFL:** Tianyu Yang, Antoni B. Chan.
  "Recurrent Filter Learning for Visual Tracking." ICCV workshop (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/Yang_Recurrent_Filter_Learning_ICCV_2017_paper.pdf)]


### CVPR2017

* **ECO:** Martin Danelljan, Goutam Bhat, Fahad Shahbaz Khan, Michael Felsberg. 
  "ECO: Efficient Convolution Operators for Tracking." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Danelljan_ECO_Efficient_Convolution_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Danelljan_ECO_Efficient_Convolution_2017_CVPR_supplemental.pdf)]
  [[project](http://www.cvl.isy.liu.se/research/objrec/visualtracking/ecotrack/index.html)]
  [[github](https://github.com/martin-danelljan/ECO)]

* **CFNet:** Jack Valmadre, Luca Bertinetto, João F. Henriques, Andrea Vedaldi, Philip H. S. Torr.
  "End-to-end representation learning for Correlation Filter based tracking." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Valmadre_End-To-End_Representation_Learning_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Valmadre_End-To-End_Representation_Learning_2017_CVPR_supplemental.pdf)]
  [[project](http://www.robots.ox.ac.uk/~luca/cfnet.html)]
  [[github](https://github.com/bertinetto/cfnet)]

* **CACF:** Matthias Mueller, Neil Smith, Bernard Ghanem. 
  "Context-Aware Correlation Filter Tracking." CVPR (2017 **oral**). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Mueller_Context-Aware_Correlation_Filter_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Mueller_Context-Aware_Correlation_Filter_2017_CVPR_supplemental.zip)]
  [[project](https://ivul.kaust.edu.sa/Pages/pub-ca-cf-tracking.aspx)]
  [[code](https://github.com/thias15/Context-Aware-CF-Tracking)]

* **RaF:** Le Zhang, Jagannadan Varadarajan, Ponnuthurai Nagaratnam Suganthan, Narendra Ahuja and Pierre Moulin
  "Robust Visual Tracking Using Oblique Random Forests." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_Robust_Visual_Tracking_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Zhang_Robust_Visual_Tracking_2017_CVPR_supplemental.pdf)]
  [[project](https://sites.google.com/site/zhangleuestc/incremental-oblique-random-forest)]
  [[code](https://github.com/ZhangLeUestc/Incremental-Oblique-Random-Forest)]

* **MCPF:** Tianzhu Zhang, Changsheng Xu, Ming-Hsuan Yang. 
  "Multi-Task Correlation Particle Filter for Robust Object Tracking." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_Multi-Task_Correlation_Particle_CVPR_2017_paper.pdf)]
  [[project](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/mcpf.html)]
  [[code](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/mcpf.html)]

* **ACFN:** Jongwon Choi, Hyung Jin Chang, Sangdoo Yun, Tobias Fischer, Yiannis Demiris, and Jin Young Choi.
  "Attentional Correlation Filter Network for Adaptive Visual Tracking." CVPR (2017).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Choi_Attentional_Correlation_Filter_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Choi_Attentional_Correlation_Filter_2017_CVPR_supplemental.pdf)]
  [[project](https://sites.google.com/site/jwchoivision/home/acfn-1)]
  [[test code](https://drive.google.com/file/d/0B0ZkG8zaRQoLQUswbW9qSWFaU0U/view?usp=drive_web)]
  [[training code](https://drive.google.com/file/d/0B0ZkG8zaRQoLZVVranBnbHlydnM/view?usp=drive_web)]

* **LMCF:** Mengmeng Wang, Yong Liu, Zeyi Huang. 
  "Large Margin Object Tracking with Circulant Feature Maps." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_Large_Margin_Object_CVPR_2017_paper.pdf)]
  [[zhihu](https://zhuanlan.zhihu.com/p/25761718)]

* **ADNet:** Sangdoo Yun, Jongwon Choi, Youngjoon Yoo, Kimin Yun, Jin Young Choi.
  "Action-Decision Networks for Visual Tracking with Deep Reinforcement Learning." CVPR (2017 **Spotlight**). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Yun_Action-Decision_Networks_for_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Yun_Action-Decision_Networks_for_2017_CVPR_supplemental.pdf)]
  [[project](https://sites.google.com/view/cvpr2017-adnet)]

* **CSR-DCF:** Alan Lukežič, Tomáš Vojíř, Luka Čehovin, Jiří Matas, Matej Kristan. 
  "Discriminative Correlation Filter with Channel and Spatial Reliability." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Lukezic_Discriminative_Correlation_Filter_CVPR_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_cvpr_2017/supplemental/Lukezic_Discriminative_Correlation_Filter_2017_CVPR_supplemental.pdf)]
  [[code](https://github.com/alanlukezic/csr-dcf)]

* **BranchOut:** Bohyung Han, Jack Sim, Hartwig Adam.
  "BranchOut: Regularization for Online Ensemble Tracking with Convolutional Neural Networks." CVPR (2017). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Han_BranchOut_Regularization_for_CVPR_2017_paper.pdf)]

* **AMCT:** Donghun Yeo, Jeany Son, Bohyung Han, Joonhee Han.
  "Superpixel-based Tracking-by-Segmentation using Markov Chains." CVPR (2017).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Yeo_Superpixel-Based_Tracking-By-Segmentation_Using_CVPR_2017_paper.pdf)]

* **SANet:** Heng Fan, Haibin Ling. 
  "SANet: Structure-Aware Network for Visual Tracking." CVPRW (2017). 
  [[paper](https://arxiv.org/pdf/1611.06878.pdf)]
  [[project](http://www.dabi.temple.edu/~hbling/code/SANet/SANet.html)]
  [[code](http://www.dabi.temple.edu/~hbling/code/SANet/sanet_code.zip)]

### ECCV2016

* **SiameseFC:** Luca Bertinetto, Jack Valmadre, João F. Henriques, Andrea Vedaldi, Philip H.S. Torr. 
  "Fully-Convolutional Siamese Networks for Object Tracking." ECCV workshop (2016). 
  [[paper](http://120.52.73.78/arxiv.org/pdf/1606.09549v2.pdf)]
  [[project](http://www.robots.ox.ac.uk/~luca/siamese-fc.html)]
  [[github](https://github.com/bertinetto/siamese-fc)]

* **GOTURN:** David Held, Sebastian Thrun, Silvio Savarese. 
  "Learning to Track at 100 FPS with Deep Regression Networks." ECCV (2016). 
  [[paper](http://davheld.github.io/GOTURN/GOTURN.pdf)]
  [[project](http://davheld.github.io/GOTURN/GOTURN.html)]
  [[github](https://github.com/davheld/GOTURN)]

* **C-COT:** Martin Danelljan, Andreas Robinson, Fahad Khan, Michael Felsberg. 
  "Beyond Correlation Filters: Learning Continuous Convolution Operators for Visual Tracking." ECCV (2016). 
  [[paper](http://www.cvl.isy.liu.se/research/objrec/visualtracking/conttrack/C-COT_ECCV16.pdf)]
  [[project](http://www.cvl.isy.liu.se/research/objrec/visualtracking/conttrack/index.html)]
  [[github](https://github.com/martin-danelljan/Continuous-ConvOp)]

* **CF+AT:** Adel Bibi, Matthias Mueller, and Bernard Ghanem. 
  "Target Response Adaptation for Correlation Filter Tracking." ECCV (2016). 
  [[paper](http://www.adelbibi.com/papers/ECCV2016/Target_Adap.pdf)]
  [[project](https://ivul.kaust.edu.sa/Pages/pub-target-response-adaptation.aspx)]
  [[github](https://github.com/adelbibi/Target-Response-Adaptation-for-Correlation-Filter-Tracking)]

* Yao Sui, Ziming Zhang,  Guanghui Wang, Yafei Tang, Li Zhang. 
  "Real-Time Visual Tracking: Promoting the Robustness of Correlation Filter Learning." ECCV (2016). 
  [[paper](http://120.52.73.78/arxiv.org/pdf/1608.08173.pdf)]

* Yao Sui, Guanghui Wang, Yafei Tang, Li Zhang. 
  "Tracking Completion." ECCV (2016). 
  [[paper](http://120.52.73.78/arxiv.org/pdf/1608.08171v1.pdf)]

### CVPR2016

* **MDNet:** Nam, Hyeonseob, and Bohyung Han. 
  "Learning Multi-Domain Convolutional Neural Networks for Visual Tracking." CVPR (2016).
  [[paper](http://arxiv.org/pdf/1510.07945v2.pdf)]
  [[VOT_presentation](http://votchallenge.net/vot2015/download/presentation_Hyeonseob.pdf)]
  [[project](http://cvlab.postech.ac.kr/research/mdnet/)]
  [[github](https://github.com/HyeonseobNam/MDNet)]

* **SINT:** Ran Tao, Efstratios Gavves, Arnold W.M. Smeulders. 
  "Siamese Instance Search for Tracking." CVPR (2016).
  [[paper](https://staff.science.uva.nl/r.tao/pub/TaoCVPR2016.pdf)]
  [[project](https://staff.fnwi.uva.nl/r.tao/projects/SINT/SINT_proj.html)]

* **SCT:** Jongwon Choi, Hyung Jin Chang, Jiyeoup Jeong, Yiannis Demiris, and Jin Young Choi.
  "Visual Tracking Using Attention-Modulated Disintegration and Integration." CVPR (2016).
  [[paper](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Choi_Visual_Tracking_Using_CVPR_2016_paper.pdf)]
  [[project](https://sites.google.com/site/jwchoivision/home/sct)]

* **STCT:** Lijun Wang, Wanli Ouyang, Xiaogang Wang, and Huchuan Lu.
  "STCT: Sequentially Training Convolutional Networks for Visual Tracking." CVPR (2016).
  [[paper](http://www.ee.cuhk.edu.hk/~wlouyang/Papers/WangLJ_CVPR16.pdf)]
  [[github](https://github.com/scott89/STCT)]

* **SRDCFdecon:** Martin Danelljan, Gustav Häger, Fahad Khan, Michael Felsberg. 
  "Adaptive Decontamination of the Training Set: A Unified Formulation for Discriminative Visual Tracking." CVPR (2016).
  [[paper](https://www.cvl.isy.liu.se/research/objrec/visualtracking/decontrack/AdaptiveDecon_CVPR16.pdf)]
  [[project](https://www.cvl.isy.liu.se/research/objrec/visualtracking/decontrack/index.html)]

* **HDT:** Yuankai Qi, Shengping Zhang, Lei Qin, Hongxun Yao, Qingming Huang, Jongwoo Lim, Ming-Hsuan Yang. 
  "Hedged Deep Tracking." CVPR (2016). 
  [[paper](http://faculty.ucmerced.edu/mhyang/papers/cvpr16_hedge_tracking.pdf)]
  [[project](https://sites.google.com/site/yuankiqi/hdt/)]

* **Staple:** Luca Bertinetto, Jack Valmadre, Stuart Golodetz, Ondrej Miksik, Philip H.S. Torr. 
  "Staple: Complementary Learners for Real-Time Tracking." CVPR (2016). 
  [[paper](http://120.52.73.75/arxiv.org/pdf/1512.01355v2.pdf)]
  [[project](http://www.robots.ox.ac.uk/~luca/staple.html)]
  [[github](https://github.com/bertinetto/staple)]

* **EBT:** Gao Zhu, Fatih Porikli, and Hongdong Li.
  "Beyond Local Search: Tracking Objects Everywhere with Instance-Specific Proposals." CVPR (2016). 
  [[paper](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhu_Beyond_Local_Search_CVPR_2016_paper.pdf)]
  [[exe](http://www.votchallenge.net/vot2016/download/02_EBT.zip)]

* **DLSSVM:** Jifeng Ning, Jimei Yang, Shaojie Jiang, Lei Zhang and Ming-Hsuan Yang. 
  "Object Tracking via Dual Linear Structured SVM and Explicit Feature Map." CVPR (2016). 
  [[paper](http://www4.comp.polyu.edu.hk/~cslzhang/paper/cvpr16/DLSSVM.pdf)]
  [[code](http://www4.comp.polyu.edu.hk/~cslzhang/code/DLSSVM_CVPR.zip)]
  [[project](http://www4.comp.polyu.edu.hk/~cslzhang/DLSSVM/DLSSVM.htm)]

### NIPS2016
* **Learnet:** Luca Bertinetto, João F. Henriques, Jack Valmadre, Philip H. S. Torr, Andrea Vedaldi. 
  "Learning feed-forward one-shot learners." NIPS (2016). 
  [[paper](https://arxiv.org/pdf/1606.05233v1.pdf)]

### ICCV2015

* **FCNT:** Lijun Wang, Wanli Ouyang, Xiaogang Wang, and Huchuan Lu. 
  "Visual Tracking with Fully Convolutional Networks." ICCV (2015). 
  [[paper](http://202.118.75.4/lu/Paper/ICCV2015/iccv15_lijun.pdf)]
  [[project](http://scott89.github.io/FCNT/)]
  [[github](https://github.com/scott89/FCNT)]

* **SRDCF:** Martin Danelljan, Gustav Häger, Fahad Khan, Michael Felsberg. 
  "Learning Spatially Regularized Correlation Filters for Visual Tracking." ICCV (2015). 
  [[paper](https://www.cvl.isy.liu.se/research/objrec/visualtracking/regvistrack/SRDCF_ICCV15.pdf)]
  [[project](https://www.cvl.isy.liu.se/research/objrec/visualtracking/regvistrack/)]

* **CF2:** Chao Ma, Jia-Bin Huang, Xiaokang Yang and Ming-Hsuan Yang.
  "Hierarchical Convolutional Features for Visual Tracking." ICCV (2015)
  [[paper](http://faculty.ucmerced.edu/mhyang/papers/iccv15_tracking.pdf)]
  [[project](https://sites.google.com/site/jbhuang0604/publications/cf2)]
  [[github](https://github.com/jbhuang0604/CF2)]

* Naiyan Wang, Jianping Shi, Dit-Yan Yeung and Jiaya Jia.
  "Understanding and Diagnosing Visual Tracking Systems." ICCV (2015). 
  [[paper](http://winsty.net/papers/diagnose.pdf)]
  [[project](http://winsty.net/tracker_diagnose.html)]
  [[code](http://winsty.net/diagnose/diagnose_code.zip)]\

* **DeepSRDCF:** Martin Danelljan, Gustav Häger, Fahad Khan, Michael Felsberg. 
  "Convolutional Features for Correlation Filter Based Visual Tracking." ICCV workshop (2015). 
  [[paper](https://www.cvl.isy.liu.se/research/objrec/visualtracking/regvistrack/ConvDCF_ICCV15_VOTworkshop.pdf)]
  [[project](https://www.cvl.isy.liu.se/research/objrec/visualtracking/regvistrack/)]

* **RAJSSC:** Mengdan Zhang, Junliang Xing, Jin Gao, Xinchu Shi, Qiang Wang, Weiming Hu. 
  "Joint Scale-Spatial Correlation Tracking with Adaptive Rotation Estimation." ICCV workshop (2015). 
  [[paper](http://www.cv-foundation.org//openaccess/content_iccv_2015_workshops/w14/papers/Zhang_Joint_Scale-Spatial_Correlation_ICCV_2015_paper.pdf)]
  [[poster](http://www.votchallenge.net/vot2015/download/poster_Mengdan_Zhang.pdf)]

### CVPR2015

* **MUSTer:** Zhibin Hong, Zhe Chen, Chaohui Wang, Xue Mei, Danil Prokhorov, Dacheng Tao. 
  "MUlti-Store Tracker (MUSTer): A Cognitive Psychology Inspired Approach to Object Tracking." CVPR (2015). 
  [[paper](http://openaccess.thecvf.com/content_cvpr_2015/papers/Hong_MUlti-Store_Tracker_MUSTer_2015_CVPR_paper.pdf)]
  [[project](https://sites.google.com/site/multistoretrackermuster/)]

* **LCT:** Chao Ma, Xiaokang Yang, Chongyang Zhang, Ming-Hsuan Yang.
  "Long-term Correlation Tracking." CVPR (2015).
  [[paper](http://openaccess.thecvf.com/content_cvpr_2015/papers/Ma_Long-Term_Correlation_Tracking_2015_CVPR_paper.pdf)]
  [[project](https://sites.google.com/site/chaoma99/cvpr15_tracking)]
  [[github](https://github.com/chaoma99/lct-tracker)]

* **DAT:** Horst Possegger, Thomas Mauthner, and Horst Bischof. 
  "In Defense of Color-based Model-free Tracking." CVPR (2015). 
  [[paper](https://lrs.icg.tugraz.at/pubs/possegger_cvpr15.pdf)]
  [[project](https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/dat)]
  [[code](https://lrs.icg.tugraz.at/downloads/dat-v1.0.zip)]

* **RPT:** Yang Li, Jianke Zhu and Steven C.H. Hoi. 
  "Reliable Patch Trackers: Robust Visual Tracking by Exploiting Reliable Patches." CVPR (2015). 
  [[paper](https://github.com/ihpdep/ihpdep.github.io/raw/master/papers/cvpr15_rpt.pdf)]
  [[github](https://github.com/ihpdep/rpt)]

### ICML2015

* **CNN-SVM:** Seunghoon Hong, Tackgeun You, Suha Kwak and Bohyung Han.
  "Online Tracking by Learning Discriminative Saliency Map with Convolutional Neural Network ." ICML (2015)
  [[paper](http://120.52.73.80/arxiv.org/pdf/1502.06796.pdf)]
  [[project](http://cvlab.postech.ac.kr/research/CNN_SVM/)]

### BMVC2014

* **DSST:** Martin Danelljan, Gustav Häger, Fahad Shahbaz Khan and Michael Felsberg. 
  "Accurate Scale Estimation for Robust Visual Tracking." BMVC (2014).
  [[paper](http://www.cvl.isy.liu.se/research/objrec/visualtracking/scalvistrack/ScaleTracking_BMVC14.pdf)]
  [[PAMI](http://www.cvl.isy.liu.se/en/research/objrec/visualtracking/scalvistrack/DSST_TPAMI.pdf)]
  [[project](http://www.cvl.isy.liu.se/en/research/objrec/visualtracking/scalvistrack/index.html)]

### ECCV2014

* **MEEM:** Jianming Zhang, Shugao Ma, and Stan Sclaroff.
  "MEEM: Robust Tracking via Multiple Experts using Entropy Minimization." ECCV (2014).
  [[paper](http://cs-people.bu.edu/jmzhang/MEEM/MEEM-eccv-preprint.pdf)]
  [[project](http://cs-people.bu.edu/jmzhang/MEEM/MEEM.html)]

* **TGPR:** Jin Gao, Haibin Ling, Weiming Hu, Junliang Xing.
  "Transfer Learning Based Visual Tracking with Gaussian Process Regression." ECCV (2014).
  [[paper](http://www.dabi.temple.edu/~hbling/publication/tgpr-eccv14.pdf)]
  [[project](http://www.dabi.temple.edu/~hbling/code/TGPR.htm)]

* **STC:** Kaihua Zhang, Lei Zhang, Ming-Hsuan Yang, David Zhang.
  "Fast Tracking via Spatio-Temporal Context Learning." ECCV (2014).
  [[paper](http://arxiv.org/pdf/1311.1939v1.pdf)]
  [[project](http://www4.comp.polyu.edu.hk/~cslzhang/STC/STC.htm)]

* **SAMF:** Yang Li, Jianke Zhu.
  "A Scale Adaptive Kernel Correlation Filter Tracker with Feature Integration." ECCV workshop (2014).
  [[paper](http://link.springer.com/content/pdf/10.1007%2F978-3-319-16181-5_18.pdf)]
  [[github](https://github.com/ihpdep/samf)]

### NIPS2013

* **DLT:** Naiyan Wang and Dit-Yan Yeung. 
  "Learning A Deep Compact Image Representation for Visual Tracking." NIPS (2013). 
  [[paper](http://winsty.net/papers/dlt.pdf)]
  [[project](http://winsty.net/dlt.html)]
  [[code](http://winsty.net/dlt/DLTcode.zip)]
 
 ### PAMI & IJCV & TIP

* **MCPF:** Tianzhu Zhang, Changsheng Xu, Ming-Hsuan Yang.
    " Learning Multi-task Correlation Particle Filters for Visual Tracking." TPAMI (2017).
      [[paper]]
      [[project](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/lmcpf.html)]
      [[code](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/Project_Tianzhu/zhang_mcpf/Source_Code/Source_Code.zip)] 

* **RSST:** Tianzhu Zhang, Changsheng Xu, Ming-Hsuan Yang.
  " Robust Structural Sparse Tracking." TPAMI (2017).
  [[paper]]
  [[project](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/rsst.html)]
  [[code](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/Project_Tianzhu/zhang_RSST/RSSTDeep/RSSTDeep_Code.zip)] 

* **fDSST:** Martin Danelljan, Gustav Häger, Fahad Khan, Michael Felsberg.
  "Discriminative Scale Space Tracking." TPAMI (2017).
  [[paper](http://www.cvl.isy.liu.se/research/objrec/visualtracking/scalvistrack/DSST_TPAMI.pdf)]
  [[project](http://www.cvl.isy.liu.se/research/objrec/visualtracking/scalvistrack/index.html)]
  [[code](http://www.cvl.isy.liu.se/research/objrec/visualtracking/scalvistrack/fDSST_code.zip)] 

* **KCF:** João F. Henriques, Rui Caseiro, Pedro Martins, Jorge Batista. 
  "High-Speed Tracking with Kernelized Correlation Filters." TPAMI (2015).
  [[paper](http://www.robots.ox.ac.uk/~joao/publications/henriques_tpami2015.pdf)]
  [[project](http://www.robots.ox.ac.uk/~joao/circulant/)]

* **CLRST:** Tianzhu Zhang, Si Liu, Narendra Ahuja, Ming-Hsuan Yang, Bernard Ghanem.  
  "Robust Visual Tracking Via Consistent Low-Rank Sparse Learning." IJCV (2015). 
  [[paper](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/tianzhu%20zhang_files/Journal%20Articles/IJCV15_zhang_Low-Rank%20Sparse%20Learning.pdf)]
  [[project](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/Project_Tianzhu/zhang_IJCV14/Robust%20Visual%20Tracking%20Via%20Consistent%20Low-Rank%20Sparse.html)]
  [[code](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/Project_Tianzhu/zhang_IJCV14/material/LRT_Code.zip)]

* **DNT:** Zhizhen Chi, Hongyang Li, Huchuan Lu, Ming-Hsuan Yang. 
  "Dual Deep Network for Visual Tracking." TIP (2017). 
  [[paper](https://arxiv.org/pdf/1612.06053v1.pdf)]

* **DRT:** Junyu Gao, Tianzhu Zhang, Xiaoshan Yang, Changsheng Xu. 
  "Deep Relative Tracking." TIP (2017). 
  [[paper](http://ieeexplore.ieee.org/abstract/document/7828108/)]

* **BIT:** Bolun Cai, Xiangmin Xu, Xiaofen Xing, Kui Jia, Jie Miao, Dacheng Tao.
  "BIT: Biologically Inspired Tracker." TIP (2016). 
  [[paper](http://caibolun.github.io/papers/BIT_TIP.pdf)]
  [[project](http://caibolun.github.io/BIT/index.html)]
  [[github](https://github.com/caibolun/BIT)]

* **CNT:** Kaihua Zhang, Qingshan Liu, Yi Wu, Minghsuan Yang. 
  "Robust Visual Tracking via Convolutional Networks Without Training." TIP (2016). 
  [[paper](http://kaihuazhang.net/CNT.pdf)]
  [[code](http://kaihuazhang.net/CNT_matlab.rar)]
  


## Benchmarks
* **WebUAV-3M:** Chunhui Zhang, Guanjie Huang, Li Liu, Shan Huang, Yinan Yang, Xiang Wan, Shiming Ge, Dacheng Tao.<br />
  "WebUAV-3M: A Benchmark for Unveiling the Power of Million-Scale Deep UAV Tracking." TPAMI (2023).
  [[paper](https://arxiv.org/abs/2201.07425)] 
  [[project](https://github.com/983632847/WebUAV-3M)]
  
* **LaSOT:** Heng Fan, Liting Lin, Fan Yang, Peng Chu, Ge Deng, Sijia Yu, Hexin Bai, Yong Xu, Chunyuan Liao, Haibin Ling.
  "LaSOT: A High-quality Benchmark for Large-scale Single Object Tracking.." CVPR (2019). 
  [[paper](https://arxiv.org/pdf/1809.07845.pdf)]
  [[project](https://cis.temple.edu/lasot/)]

* **OxUvA long-term dataset+benchmark:** Jack Valmadre, Luca Bertinetto, João F. Henriques, Ran Tao, Andrea Vedaldi, Arnold Smeulders, Philip Torr, Efstratios Gavves.<br />
  "Long-term Tracking in the Wild: a Benchmark." ECCV (2018).
  [[paper](https://arxiv.org/pdf/1803.09502.pdf)]
  [[project](https://oxuva.github.io/long-term-tracking-benchmark/)]

* **TrackingNet:** Matthias Müller, Adel Bibi, Silvio Giancola, Salman Al-Subaihi, Bernard Ghanem.<br />
  "TrackingNet: A Large-Scale Dataset and Benchmark for Object Tracking in the Wild." ECCV (2018).
  [[project](https://silviogiancola.github.io/publication/2018-03-trackingnet/details/)]
  [[paper](https://arxiv.org/pdf/1803.10794.pdf)] 

* **UAVDT:** Dawei Du, Yuankai Qi, Hongyang Yu, Yifang Yang, Kaiwen Duan, GuoRong Li, Weigang Zhang,  Weihai; Qingming Huang, Qi Tian.<br />
  "The Unmanned Aerial Vehicle Benchmark: Object Detection and Tracking." ECCV (2018).
  [[paper](https://arxiv.org/pdf/1804.00518.pdf)]

* **Dataset-AMP:** Luka Čehovin Zajc; Alan Lukežič; Aleš Leonardis; Matej Kristan.
  "Beyond Standard Benchmarks: Parameterizing Performance Evaluation in Visual Object Tracking." ICCV (2017).
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Zajc_Beyond_Standard_Benchmarks_ICCV_2017_paper.pdf)]

* **Dataset-Nfs:** Hamed Kiani Galoogahi, Ashton Fagg, Chen Huang, Deva Ramanan and Simon Lucey.
  "Need for Speed: A Benchmark for Higher Frame Rate Object Tracking." ICCV (2017)
  [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Galoogahi_Need_for_Speed_ICCV_2017_paper.pdf)]
  [[supp](http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Galoogahi_Need_for_Speed_ICCV_2017_supplemental.pdf)]
  [[project](http://ci2cv.net/nfs/index.html)]

* **Dataset-DTB70:** Siyi Li, Dit-Yan Yeung.
  "Visual Object Tracking for Unmanned Aerial Vehicles: A Benchmark and New Motion Models." AAAI (2017)
  [[paper](http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14338/14292)]
  [[project](https://github.com/flyers/drone-tracking)]
  [[dataset](https://www.dropbox.com/s/s1fj99s2six4lrs/DTB70.tar.gz?dl=0)]

* **Dataset-UAV123:** Matthias Mueller, Neil Smith and Bernard Ghanem.
  "A Benchmark and Simulator for UAV Tracking." ECCV (2016)
  [[paper](https://ivul.kaust.edu.sa/Documents/Publications/2016/A%20Benchmark%20and%20Simulator%20for%20UAV%20Tracking.pdf)]
  [[project](https://ivul.kaust.edu.sa/Pages/pub-benchmark-simulator-uav.aspx)]
  [[dataset](https://ivul.kaust.edu.sa/Pages/Dataset-UAV123.aspx)]

* **Dataset-TColor-128:** Pengpeng Liang, Erik Blasch, Haibin Ling.
  "Encoding color information for visual tracking: Algorithms and benchmark." TIP (2015)
  [[paper](http://www.dabi.temple.edu/~hbling/publication/TColor-128.pdf)]
  [[project](http://www.dabi.temple.edu/~hbling/data/TColor-128/TColor-128.html)]
  [[dataset](http://www.dabi.temple.edu/~hbling/data/TColor-128/Temple-color-128.zip)]

* **Dataset-NUS-PRO:** Annan Li, Min Lin, Yi Wu, Ming-Hsuan Yang, and Shuicheng Yan.
  "NUS-PRO: A New Visual Tracking Challenge." PAMI (2015)
  [[paper](http://faculty.ucmerced.edu/mhyang/papers/pami15_nus_pro.pdf)]
  [[project](https://sites.google.com/site/li00annan/nus-pro)]
  [[Data_360](https://d9fca6.lc.yunpan.cn/lk/cqKIc6DU3t2eJ)(code:bf28)]
  [[Data_baidu]](https://pan.baidu.com/s/1pJHvbSn#list/path=%2F)]
  [[View_360](https://6aa275.lc.yunpan.cn/lk/cqK479PfzDrPX)(code:515a)]
  [[View_baidu]](https://pan.baidu.com/s/1hqKXcuK)]

* **Dataset-PTB:** Shuran Song and Jianxiong Xiao.
  "Tracking Revisited using RGBD Camera: Unified Benchmark and Baselines." ICCV (2013)
  [[paper](http://vision.princeton.edu/projects/2013/tracking/paper.pdf)]
  [[project](http://tracking.cs.princeton.edu/)]
  [[5 validation](http://tracking.cs.princeton.edu/ValidationSet.zip)]
  [[95 evaluation](http://tracking.cs.princeton.edu/EvaluationSet.tgz)]

* **Dataset-ALOV300+:** Arnold W. M. Smeulders, Dung M. Chu, Rita Cucchiara, Simone Calderara, Afshin Dehghan, Mubarak Shah.
  "Visual Tracking: An Experimental Survey." PAMI (2014)
  [[paper](http://crcv.ucf.edu/papers/Tracking_Survey.pdf)]
  [[project](http://imagelab.ing.unimore.it/dsm/)]
  [Mirror Link:ALOV300++ Dataset](http://crcv.ucf.edu/people/phd_students/afshin/ALOV300/Frames.zip)
  [Mirror Link:ALOV300++ Groundtruth](http://crcv.ucf.edu/people/phd_students/afshin/ALOV300/GT.zip)

* **OTB2013:** Wu, Yi, Jongwoo Lim, and Minghsuan Yang. 
  "Online Object Tracking: A Benchmark." CVPR (2013).
  [[paper](http://faculty.ucmerced.edu/mhyang/papers/cvpr13_benchmark.pdf)]

* **OTB2015:** Wu, Yi, Jongwoo Lim, and Minghsuan Yang. 
  "Object Tracking Benchmark." TPAMI (2015).
  [[paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7001050&tag=1)]
  [[project](http://cvlab.hanyang.ac.kr/tracker_benchmark/index.html)]

* **Dataset-VOT:**
  **[[project](http://www.votchallenge.net/)]**

**[[VOT13_paper_ICCV](http://www.votchallenge.net/vot2013/Download/vot_2013_paper.pdf)]The Visual Object Tracking VOT2013 challenge results**

**[[VOT14_paper_ECCV](http://www.votchallenge.net/vot2014/download/vot_2014_paper.pdf)]The Visual Object Tracking VOT2014 challenge results**

**[[VOT15_paper_ICCV](http://www.votchallenge.net/vot2015/download/vot_2015_paper.pdf)]The Visual Object Tracking VOT2015 challenge results**

**[[VOT16_paper_ECCV](http://www.votchallenge.net/vot2016/download/vot_2016_paper.pdf)]The Visual Object Tracking VOT2016 challenge results**

**[[VOT17_paper_ICCV](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w28/Kristan_The_Visual_Object_ICCV_2017_paper.pdf)]The Visual Object Tracking VOT2017 challenge results**


## Distinguished Researchers and Teams
Distinguished visual tracking researchers who have published +3 papers which have a major impact on the field of visual tracking and are still active in the field of visual tracking.(Names listed in no particular order.)

* [Ming-Hsuan Yang](http://faculty.ucmerced.edu/mhyang/)
* [Haibin Ling](http://www.dabi.temple.edu/~hbling/)
* [Huchuan Lu](http://ice.dlut.edu.cn/lu/)
* [Hongdong Li](http://users.cecs.anu.edu.au/~hongdong/)
* [Lei Zhang](http://www4.comp.polyu.edu.hk/~cslzhang/)
* [Matej Kristan](http://www.vicos.si/People/Matejk)
* [João F. Henriques](http://www.robots.ox.ac.uk/~joao/)
* [Martin Danelljan](http://users.isy.liu.se/cvl/marda26/)
* [Kaihua Zhang](http://kaihuazhang.net/)
* [Hamed Kiani](http://www.hamedkiani.com/)
* [Luca Bertinetto](http://www.robots.ox.ac.uk/~luca/index.html)
* [Tianzhu Zhang](http://nlpr-web.ia.ac.cn/mmc/homepage/tzzhang/index.html)
* [Chao Ma](https://www.chaoma.info/)
* [Yibing Song](https://ybsong00.github.io/)
* [Dong Wang](http://www.escience.cn/people/wangdongdut/index.html)
* [**Torr Vision Group**](http://www.robots.ox.ac.uk/~tvg/people.php)
* [**Computer Vision Laboratory, POSTECH**](http://cvlab.postech.ac.kr/lab/index.php)
